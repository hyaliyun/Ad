<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Ad</title>
    <meta name="description" content="Ad">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/assets/style.CAM3H9Gm.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.7uGsmnbX.js"></script>
    <link rel="modulepreload" href="/assets/chunks/theme.QB-wH4Se.js">
    <link rel="modulepreload" href="/assets/chunks/framework.B1z0IdBH.js">
    <link rel="modulepreload" href="/assets/guide_32.md.Cx-u0Hcq.lean.js">
    <link rel="icon" href="/logo.svg">
    <link rel="icon" type="image/svg+xml" href="/images/logo.png">
    <meta name="theme-color" content="#3c8772">
    <meta property="og:url" content="https://www.252x.com">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Ad">
    <meta property="og:description" content="Ad">
    <meta property="og:image" content="/images/logo.png">
    <meta name="twitter:site" content="@book">
    <meta name="twitter:card" content="summary">
    <link rel="preconnect" href="https://f.543x.com">
    <script>(()=>{const e=(o,r,t=!1)=>{const s=localStorage.getItem(o);(s?s!=="false":t)&&document.documentElement.classList.add(r)};e("vue-docs-prefer-composition","prefer-composition",!0),e("vue-docs-prefer-sfc","prefer-sfc",!0),window.__VUE_BANNER_ID__="vt2024_1",e(`vue-docs-banner-${__VUE_BANNER_ID__}`,"banner-dismissed")})();</script>
    <script>location.search.includes("?uwu")&&document.documentElement.classList.add("uwu");</script>
    <script src="https://cdn.usefathom.com/script.js" data-site="XNOLWPLB" data-spa="auto" defer></script>
    <script src="https://vueschool.io/banner.js?affiliate=book&amp;type=top" async></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
  </head>
  <body>
    <div id="app"><div class="VPApp" data-v-e4982c5a><!--[--><span tabindex="-1" data-v-ebeb79d9></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-ebeb79d9>Skip to content</a><!--]--><!----><!--[--><div class="banner" data-v-8f28d446><p class="vt-banner-text" data-v-8f28d446><span class="vt-text-primary" data-v-8f28d446>VueConf Toronto</span><span class="vt-tagline" data-v-8f28d446> - Join the premier TypeScript conference</span><a target="_blank" class="vt-primary-action" href="https://www.543x.com" data-v-8f28d446> Register </a></p><button data-v-8f28d446><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="close" data-v-8f28d446><path d="M18.9,10.9h-6v-6c0-0.6-0.4-1-1-1s-1,0.4-1,1v6h-6c-0.6,0-1,0.4-1,1s0.4,1,1,1h6v6c0,0.6,0.4,1,1,1s1-0.4,1-1v-6h6c0.6,0,1-0.4,1-1S19.5,10.9,18.9,10.9z"></path></svg></button><p class="vt-banner-text vt-coupon" data-v-8f28d446><span class="vt-text-primary" data-v-8f28d446>www</span> 543x <span class="vt-text-primary" data-v-8f28d446>.com</span></p></div><!--]--><header class="VPNav nav-bar stick" data-v-e4982c5a data-v-9cbed0dc><div class="VPNavBar" data-v-9cbed0dc data-v-78ea45ed><div class="container" data-v-78ea45ed><a class="VPNavBarTitle" href="/" data-v-78ea45ed data-v-4b84c549><!--[--><svg class="logo" viewBox="0 0 128 128" width="24" height="24" data-v-4b84c549><path fill="#42b883" d="M78.8,10L64,35.4L49.2,10H0l64,110l64-110C128,10,78.8,10,78.8,10z" data-v-4b84c549></path><path fill="#35495e" d="M78.8,10L64,35.4L49.2,10H25.6L64,76l38.4-66H78.8z" data-v-4b84c549></path></svg><span class="text" data-v-4b84c549>Vue.js</span><!--]--></a><div class="content" data-v-78ea45ed><div class="VPNavBarSearch search" data-v-78ea45ed><!----><div id="docsearch"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><!----></button></div></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-78ea45ed data-v-2cfd1945><span id="main-nav-aria-label" class="visually-hidden" data-v-2cfd1945>Main Navigation</span><!--[--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">data <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/drive/1.html"><!--[-->data1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/2.html"><!--[-->data2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/3.html"><!--[-->data3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/4.html"><!--[-->data4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/5.html"><!--[-->data5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/6.html"><!--[-->data6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/7.html"><!--[-->data7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/8.html"><!--[-->data8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/9.html"><!--[-->data9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/10.html"><!--[-->data10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/11.html"><!--[-->data11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/12.html"><!--[-->data12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/13.html"><!--[-->data13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/14.html"><!--[-->data14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/15.html"><!--[-->data15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/16.html"><!--[-->data16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/17.html"><!--[-->data17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/18.html"><!--[-->data18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/19.html"><!--[-->data19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/20.html"><!--[-->data20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/21.html"><!--[-->data21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/22.html"><!--[-->data22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/23.html"><!--[-->data23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/24.html"><!--[-->data24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/25.html"><!--[-->data25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/26.html"><!--[-->data26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/27.html"><!--[-->data27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/28.html"><!--[-->data28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/29.html"><!--[-->data29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/30.html"><!--[-->data30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/31.html"><!--[-->data31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/32.html"><!--[-->data32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/33.html"><!--[-->data33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/34.html"><!--[-->data34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/35.html"><!--[-->data35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/36.html"><!--[-->data36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/37.html"><!--[-->data37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/38.html"><!--[-->data38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/39.html"><!--[-->data39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/40.html"><!--[-->data40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/41.html"><!--[-->data41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/42.html"><!--[-->data42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/43.html"><!--[-->data43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/44.html"><!--[-->data44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/45.html"><!--[-->data45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/46.html"><!--[-->data46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/47.html"><!--[-->data47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/48.html"><!--[-->data48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/49.html"><!--[-->data49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/50.html"><!--[-->data50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/51.html"><!--[-->data51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/52.html"><!--[-->data52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/53.html"><!--[-->data53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/54.html"><!--[-->data54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/55.html"><!--[-->data55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/56.html"><!--[-->data56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/57.html"><!--[-->data57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/58.html"><!--[-->data58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/59.html"><!--[-->data59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/60.html"><!--[-->data60<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">grok <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/grok/1.html"><!--[-->grok1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/2.html"><!--[-->grok2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/3.html"><!--[-->grok3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/4.html"><!--[-->grok4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/5.html"><!--[-->grok5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/6.html"><!--[-->grok6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/7.html"><!--[-->grok7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/8.html"><!--[-->grok8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/9.html"><!--[-->grok9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/10.html"><!--[-->grok10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/11.html"><!--[-->grok11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/12.html"><!--[-->grok12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/13.html"><!--[-->grok13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/14.html"><!--[-->grok14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/15.html"><!--[-->grok15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/16.html"><!--[-->grok16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/17.html"><!--[-->grok17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/18.html"><!--[-->grok18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/19.html"><!--[-->grok19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/20.html"><!--[-->grok20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/21.html"><!--[-->grok21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/22.html"><!--[-->grok22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/23.html"><!--[-->grok23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/24.html"><!--[-->grok24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/25.html"><!--[-->grok25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/26.html"><!--[-->grok26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/27.html"><!--[-->grok27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/28.html"><!--[-->grok28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/29.html"><!--[-->grok29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/30.html"><!--[-->grok30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/31.html"><!--[-->grok31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/32.html"><!--[-->grok32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/33.html"><!--[-->grok33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/34.html"><!--[-->grok34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/35.html"><!--[-->grok35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/36.html"><!--[-->grok36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/37.html"><!--[-->grok37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/38.html"><!--[-->grok38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/39.html"><!--[-->grok39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/40.html"><!--[-->grok40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/41.html"><!--[-->grok41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/42.html"><!--[-->grok42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/43.html"><!--[-->grok43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/44.html"><!--[-->grok44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/45.html"><!--[-->grok45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/46.html"><!--[-->grok46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/47.html"><!--[-->grok47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/48.html"><!--[-->grok48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/49.html"><!--[-->grok49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/50.html"><!--[-->grok50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/51.html"><!--[-->grok51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/52.html"><!--[-->grok52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/53.html"><!--[-->grok53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/54.html"><!--[-->grok54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/55.html"><!--[-->grok55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/56.html"><!--[-->grok56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/57.html"><!--[-->grok57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/58.html"><!--[-->grok58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/59.html"><!--[-->grok59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/60.html"><!--[-->grok60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/61.html"><!--[-->grok61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/62.html"><!--[-->grok62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/63.html"><!--[-->grok63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/64.html"><!--[-->grok64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/65.html"><!--[-->grok65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/66.html"><!--[-->grok66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/67.html"><!--[-->grok67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/68.html"><!--[-->grok68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup active" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">wiki <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/guide/1.html"><!--[-->wiki1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/2.html"><!--[-->wiki2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/3.html"><!--[-->wiki3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/4.html"><!--[-->wiki4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/5.html"><!--[-->wiki5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/6.html"><!--[-->wiki6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/7.html"><!--[-->wiki7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/8.html"><!--[-->wiki8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/9.html"><!--[-->wiki9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/10.html"><!--[-->wiki10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/11.html"><!--[-->wiki11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/12.html"><!--[-->wiki12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/13.html"><!--[-->wiki13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/14.html"><!--[-->wiki14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/15.html"><!--[-->wiki15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/16.html"><!--[-->wiki16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/17.html"><!--[-->wiki17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/18.html"><!--[-->wiki18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/19.html"><!--[-->wiki19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/20.html"><!--[-->wiki20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/21.html"><!--[-->wiki21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/22.html"><!--[-->wiki22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/23.html"><!--[-->wiki23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/24.html"><!--[-->wiki24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/25.html"><!--[-->wiki25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/26.html"><!--[-->wiki26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/27.html"><!--[-->wiki27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/28.html"><!--[-->wiki28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/29.html"><!--[-->wiki29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/30.html"><!--[-->wiki30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/31.html"><!--[-->wiki31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/32.html"><!--[-->wiki32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/33.html"><!--[-->wiki33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/34.html"><!--[-->wiki34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/35.html"><!--[-->wiki35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/36.html"><!--[-->wiki36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/37.html"><!--[-->wiki37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/38.html"><!--[-->wiki38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/39.html"><!--[-->wiki39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/40.html"><!--[-->wiki40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/41.html"><!--[-->wiki41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/42.html"><!--[-->wiki42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/43.html"><!--[-->wiki43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/44.html"><!--[-->wiki44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/45.html"><!--[-->wiki45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/46.html"><!--[-->wiki46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/47.html"><!--[-->wiki47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/48.html"><!--[-->wiki48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/49.html"><!--[-->wiki49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/50.html"><!--[-->wiki50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/51.html"><!--[-->wiki51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/52.html"><!--[-->wiki52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/53.html"><!--[-->wiki53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/54.html"><!--[-->wiki54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/55.html"><!--[-->wiki55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/56.html"><!--[-->wiki56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/57.html"><!--[-->wiki57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/58.html"><!--[-->wiki58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/59.html"><!--[-->wiki59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/60.html"><!--[-->wiki60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/61.html"><!--[-->wiki61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/62.html"><!--[-->wiki62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/63.html"><!--[-->wiki63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/64.html"><!--[-->wiki64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/65.html"><!--[-->wiki65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/66.html"><!--[-->wiki66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/67.html"><!--[-->wiki67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/68.html"><!--[-->wiki68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">deep <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/1.html"><!--[-->deep1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/2.html"><!--[-->deep2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/3.html"><!--[-->deep3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/4.html"><!--[-->deep4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/5.html"><!--[-->deep5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/6.html"><!--[-->deep6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/7.html"><!--[-->deep7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/8.html"><!--[-->deep8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/9.html"><!--[-->deep9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/10.html"><!--[-->deep10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/11.html"><!--[-->deep11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/12.html"><!--[-->deep12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/13.html"><!--[-->deep13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/14.html"><!--[-->deep14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/15.html"><!--[-->deep15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/16.html"><!--[-->deep16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/17.html"><!--[-->deep17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/18.html"><!--[-->deep18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/19.html"><!--[-->deep19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/20.html"><!--[-->deep20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/21.html"><!--[-->deep21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/22.html"><!--[-->deep22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/23.html"><!--[-->deep23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/24.html"><!--[-->deep24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/25.html"><!--[-->deep25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/26.html"><!--[-->deep26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/27.html"><!--[-->deep27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/28.html"><!--[-->deep28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/29.html"><!--[-->deep29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/30.html"><!--[-->deep30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/31.html"><!--[-->deep31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/32.html"><!--[-->deep32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/33.html"><!--[-->deep33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/34.html"><!--[-->deep34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/35.html"><!--[-->deep35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/36.html"><!--[-->deep36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/37.html"><!--[-->deep37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/38.html"><!--[-->deep38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/39.html"><!--[-->deep39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/40.html"><!--[-->deep40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/41.html"><!--[-->deep41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/42.html"><!--[-->deep42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/43.html"><!--[-->deep43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/44.html"><!--[-->deep44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/45.html"><!--[-->deep45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/46.html"><!--[-->deep46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/47.html"><!--[-->deep47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/48.html"><!--[-->deep48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/49.html"><!--[-->deep49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/50.html"><!--[-->deep50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/51.html"><!--[-->deep51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/52.html"><!--[-->deep52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/53.html"><!--[-->deep53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/54.html"><!--[-->deep54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/55.html"><!--[-->deep55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/56.html"><!--[-->deep56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/57.html"><!--[-->deep57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/58.html"><!--[-->deep58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/59.html"><!--[-->deep59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/60.html"><!--[-->deep60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/61.html"><!--[-->deep61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/62.html"><!--[-->deep62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/63.html"><!--[-->deep63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/64.html"><!--[-->deep64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/65.html"><!--[-->deep65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/66.html"><!--[-->deep66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/67.html"><!--[-->deep67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/68.html"><!--[-->deep68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">quotes <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/1.html"><!--[-->quotes1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/2.html"><!--[-->quotes2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/3.html"><!--[-->quotes3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/4.html"><!--[-->quotes4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/5.html"><!--[-->quotes5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/6.html"><!--[-->quotes6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/7.html"><!--[-->quotes7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/8.html"><!--[-->quotes8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/9.html"><!--[-->quotes9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/10.html"><!--[-->quotes10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/11.html"><!--[-->quotes11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/12.html"><!--[-->quotes12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/13.html"><!--[-->quotes13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/14.html"><!--[-->quotes14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/15.html"><!--[-->quotes15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/16.html"><!--[-->quotes16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/17.html"><!--[-->quotes17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/18.html"><!--[-->quotes18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/19.html"><!--[-->quotes19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/20.html"><!--[-->quotes20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/21.html"><!--[-->quotes21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/22.html"><!--[-->quotes22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/23.html"><!--[-->quotes23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/24.html"><!--[-->quotes24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/25.html"><!--[-->quotes25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/26.html"><!--[-->quotes26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/27.html"><!--[-->quotes27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/28.html"><!--[-->quotes28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/29.html"><!--[-->quotes29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/30.html"><!--[-->quotes30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/31.html"><!--[-->quotes31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/32.html"><!--[-->quotes32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/33.html"><!--[-->quotes33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/34.html"><!--[-->quotes34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/35.html"><!--[-->quotes35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/36.html"><!--[-->quotes36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/37.html"><!--[-->quotes37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/38.html"><!--[-->quotes38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/39.html"><!--[-->quotes39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/40.html"><!--[-->quotes40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/41.html"><!--[-->quotes41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/42.html"><!--[-->quotes42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/43.html"><!--[-->quotes43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/44.html"><!--[-->quotes44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/45.html"><!--[-->quotes45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/46.html"><!--[-->quotes46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/47.html"><!--[-->quotes47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/48.html"><!--[-->quotes48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/49.html"><!--[-->quotes49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/50.html"><!--[-->quotes50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/51.html"><!--[-->quotes51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/52.html"><!--[-->quotes52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/53.html"><!--[-->quotes53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/54.html"><!--[-->quotes54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/55.html"><!--[-->quotes55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/56.html"><!--[-->quotes56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/57.html"><!--[-->quotes57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/58.html"><!--[-->quotes58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/59.html"><!--[-->quotes59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/60.html"><!--[-->quotes60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/61.html"><!--[-->quotes61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/62.html"><!--[-->quotes62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/63.html"><!--[-->quotes63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/64.html"><!--[-->quotes64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/65.html"><!--[-->quotes65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/66.html"><!--[-->quotes66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/67.html"><!--[-->quotes67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/68.html"><!--[-->quotes68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">chatai <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/1.html"><!--[-->chatai1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/2.html"><!--[-->chatai2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/3.html"><!--[-->chatai3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/4.html"><!--[-->chatai4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/5.html"><!--[-->chatai5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/6.html"><!--[-->chatai6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/7.html"><!--[-->chatai7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/8.html"><!--[-->chatai8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/9.html"><!--[-->chatai9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/10.html"><!--[-->chatai10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/11.html"><!--[-->chatai11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/12.html"><!--[-->chatai12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/13.html"><!--[-->chatai13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/14.html"><!--[-->chatai14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/15.html"><!--[-->chatai15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/16.html"><!--[-->chatai16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/17.html"><!--[-->chatai17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/18.html"><!--[-->chatai18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/19.html"><!--[-->chatai19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/20.html"><!--[-->chatai20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/21.html"><!--[-->chatai21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/22.html"><!--[-->chatai22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/23.html"><!--[-->chatai23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/24.html"><!--[-->chatai24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/25.html"><!--[-->chatai25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/26.html"><!--[-->chatai26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/27.html"><!--[-->chatai27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/28.html"><!--[-->chatai28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/29.html"><!--[-->chatai29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/30.html"><!--[-->chatai30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/31.html"><!--[-->chatai31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/32.html"><!--[-->chatai32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/33.html"><!--[-->chatai33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/34.html"><!--[-->chatai34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/35.html"><!--[-->chatai35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/36.html"><!--[-->chatai36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/37.html"><!--[-->chatai37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/38.html"><!--[-->chatai38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/39.html"><!--[-->chatai39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/40.html"><!--[-->chatai40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/41.html"><!--[-->chatai41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/42.html"><!--[-->chatai42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/43.html"><!--[-->chatai43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/44.html"><!--[-->chatai44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/45.html"><!--[-->chatai45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/46.html"><!--[-->chatai46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/47.html"><!--[-->chatai47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/48.html"><!--[-->chatai48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/49.html"><!--[-->chatai49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/50.html"><!--[-->chatai50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/51.html"><!--[-->chatai51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/52.html"><!--[-->chatai52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/53.html"><!--[-->chatai53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/54.html"><!--[-->chatai54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/55.html"><!--[-->chatai55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/56.html"><!--[-->chatai56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/57.html"><!--[-->chatai57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/58.html"><!--[-->chatai58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/59.html"><!--[-->chatai59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/60.html"><!--[-->chatai60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/61.html"><!--[-->chatai61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/62.html"><!--[-->chatai62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/63.html"><!--[-->chatai63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/64.html"><!--[-->chatai64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/65.html"><!--[-->chatai65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/66.html"><!--[-->chatai66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/67.html"><!--[-->chatai67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/68.html"><!--[-->chatai68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">library <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/library/1.html"><!--[-->library1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/2.html"><!--[-->library2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/3.html"><!--[-->library3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/4.html"><!--[-->library4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/5.html"><!--[-->library5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/6.html"><!--[-->library6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/7.html"><!--[-->library7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/8.html"><!--[-->library8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/9.html"><!--[-->library9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/10.html"><!--[-->library10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/11.html"><!--[-->library11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/12.html"><!--[-->library12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/13.html"><!--[-->library13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/14.html"><!--[-->library14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/15.html"><!--[-->library15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/16.html"><!--[-->library16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/17.html"><!--[-->library17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/18.html"><!--[-->library18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/19.html"><!--[-->library19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/20.html"><!--[-->library20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/21.html"><!--[-->library21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/22.html"><!--[-->library22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/23.html"><!--[-->library23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/24.html"><!--[-->library24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/25.html"><!--[-->library25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/26.html"><!--[-->library26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/27.html"><!--[-->library27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/28.html"><!--[-->library28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/29.html"><!--[-->library29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/30.html"><!--[-->library30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/31.html"><!--[-->library31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/32.html"><!--[-->library32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/33.html"><!--[-->library33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/34.html"><!--[-->library34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/35.html"><!--[-->library35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/36.html"><!--[-->library36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/37.html"><!--[-->library37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/38.html"><!--[-->library38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/39.html"><!--[-->library39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/40.html"><!--[-->library40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/41.html"><!--[-->library41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/42.html"><!--[-->library42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/43.html"><!--[-->library43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/44.html"><!--[-->library44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/45.html"><!--[-->library45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/46.html"><!--[-->library46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/47.html"><!--[-->library47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/48.html"><!--[-->library48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/49.html"><!--[-->library49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/50.html"><!--[-->library50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/51.html"><!--[-->library51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/52.html"><!--[-->library52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/53.html"><!--[-->library53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/54.html"><!--[-->library54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/55.html"><!--[-->library55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/56.html"><!--[-->library56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/57.html"><!--[-->library57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/58.html"><!--[-->library58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/59.html"><!--[-->library59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/60.html"><!--[-->library60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/61.html"><!--[-->library61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/62.html"><!--[-->library62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/63.html"><!--[-->library63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/64.html"><!--[-->library64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/65.html"><!--[-->library65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/66.html"><!--[-->library66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/67.html"><!--[-->library67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/68.html"><!--[-->library68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">ecosystem <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">website</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/partners/"><!--[-->partners<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/themes.html"><!--[-->website<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/newsletters.html"><!--[-->deepseekletters<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/navigation.html"><!--[-->AI Navigation<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/DeepSeek.html"><!--[-->DeepSeek-V3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/ChatGPT.html"><!--[-->ChatGPT<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/Promptes.html"><!--[-->GPT Prompts<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.474x.com" target="_blank" rel="noopener noreferrer"><!--[-->474x.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.494x.com" target="_blank" rel="noopener noreferrer"><!--[-->494x.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.64ii.com" target="_blank" rel="noopener noreferrer"><!--[-->64ii.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.81oo.com" target="_blank" rel="noopener noreferrer"><!--[-->81oo.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">Library</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://e.m44m.com/" target="_blank" rel="noopener noreferrer"><!--[-->Vue Router<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://f.m44m.com/" target="_blank" rel="noopener noreferrer"><!--[-->Pinia<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.82ii.com" target="_blank" rel="noopener noreferrer"><!--[-->tool<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">Vue</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://g.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Vue Mastery<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://h.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Vue School<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">help</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://i.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Discord<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://github.com/hyaliyun/Ad" target="_blank" rel="noopener noreferrer"><!--[-->GitHub<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->DEV<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">Ad</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://c.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->blog<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://d.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Twitter<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://e.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Activity<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://w.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->CMS<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->deepseekmagSheets<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.434x.com" target="_blank" rel="noopener noreferrer"><!--[-->Tailwind<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.434x.com" target="_blank" rel="noopener noreferrer"><!--[-->Three.js<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->youtube<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vt-link link VPNavBarMenuLink" href="/about/team.html" data-v-2cfd1945 data-v-c3f7059f><!--[-->team<!--]--><!----><!----></a><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup active" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">show <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/drive/donation.html"><!--[-->donation<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/PromptLibrary.html"><!--[-->PromptLibrary<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/prompt.html"><!--[-->prompt<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/aiprompt.html"><!--[-->Vertex AI<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/team.html"><!--[-->crypto<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/partners/"><!--[-->partners<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.3kk3.com" target="_blank" rel="noopener noreferrer"><!--[-->3kk3.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseek<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://c.4s5s.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr1<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.6n7n.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr2<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://f.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr3<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://c.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr4<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.l00m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr5<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://g.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr6<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vt-link link VPNavBarMenuLink" href="/swap/app.html" data-v-2cfd1945 data-v-c3f7059f><!--[-->swap<!--]--><!----><!----></a><!--]--><!--]--><div class="vt-flyout VPNavBarMenuGroup active VPNavBarLocale" data-v-2cfd1945 data-v-802bec0f><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false" aria-label="Select Language"><!--[--><div class="vt-locales-btn-icon-container" data-v-802bec0f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-locales-btn-icon" data-v-802bec0f><path d="M0 0h24v24H0z" fill="none"></path><path d=" M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z " class="css-c4d79v"></path></svg></div><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><!----><!--[--><!--[--><!--[--><div class="vt-menu-items x-padding" data-v-802bec0f><!--[--><div class="vt-locales-menu-item"><a href="https://g.m44m.com/guide/32.html" target="_blank" class="vt-locales-menu-item-text">简体中文 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><a href="https://github.com/hyaliyun/Ad" title="简体中文 Repository" target="_blank" class="vt-locales-btn-icon-container"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-locales-btn-icon repo"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div><!--]--></div><!----><!--]--><!--]--><!--]--></div></div></div></nav><div class="VPNavBarAppearance appearance" data-v-78ea45ed data-v-7e4f86a7><button class="vt-switch vt-switch-appearance" type="button" role="switch" aria-label="Toggle dark mode" aria-checked="false" data-v-7e4f86a7><span class="vt-switch-check"><span class="vt-switch-icon"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-sun"><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-moon"><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="vt-social-links VPNavBarSocialLinks social-links" data-v-78ea45ed data-v-44bed5da><!--[--><a class="vt-social-link is-small" href="https://github.com/hyaliyun/Ad/" title="github" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-social-link-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden">github</span></a><!--]--></div><div class="vt-flyout VPNavBarExtra extra" data-v-78ea45ed data-v-d9c85796><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-icon"><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><!----><!--[--><!--[--><div class="vt-menu-group" data-v-d9c85796><div class="vt-menu-item item" data-v-d9c85796><p class="vt-menu-label" data-v-d9c85796>Appearance</p><div class="vt-menu-action action" data-v-d9c85796><button class="vt-switch vt-switch-appearance" type="button" role="switch" aria-label="Toggle dark mode" aria-checked="false" data-v-d9c85796><span class="vt-switch-check"><span class="vt-switch-icon"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-sun"><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-moon"><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="vt-menu-group" data-v-d9c85796><div class="vt-menu-item item" data-v-d9c85796><div class="vt-social-links social-links" data-v-d9c85796><!--[--><a class="vt-social-link is-small" href="https://github.com/hyaliyun/Ad/" title="github" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-social-link-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden">github</span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><button type="button" class="vt-hamburger VPNavBarHamburger hamburger" aria-label="Mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-78ea45ed data-v-dcc88df6><span class="vt-hamburger-container"><span class="vt-hamburger-top"></span><span class="vt-hamburger-middle"></span><span class="vt-hamburger-bottom"></span></span></button></div></div></div><!----></header><!----><!----><div id="VPContent" class="VPContent" data-v-e4982c5a data-v-8b82bdb3><div class="VPContentPage" data-v-8b82bdb3><main><div style="position:relative;"><div><section data-v-bf4c880b><div class="top-banner" data-v-bf4c880b><div class="top-banner-title" data-v-bf4c880b><div class="top-banner-title-text" data-v-bf4c880b>🤔prompts chat🧠</div></div></div><div class="search-container" data-v-bf4c880b><span class="search-icon" data-v-bf4c880b>🔍</span><input type="text" class="search-input" value="" placeholder="Search..." data-v-bf4c880b><!----></div><div class="card-container" data-v-bf4c880b><!--[--><div class="poem-container" data-v-bf4c880b data-v-f19fca7f><div class="review" data-v-f19fca7f><div class="review-title" data-v-f19fca7f><span class="icon" data-v-f19fca7f>question:</span>License: CC BY 4.0 arXiv:2403.04642v1 [cs.LG] 07 Mar 2024 1]Meta 2]Georgia Institute of Technology 3]StabilityAI 4]UC Berkeley contribution [*]Work done during Meta internship contribution [**]Work done while at Meta # Teaching Large Language Models to Reason with Reinforcement Learning Alex Havrilla Yuqing Du Sharath Chandra Raparthy Christoforos Nalmpantis Jane Dwivedi-Yu Maksym Zhuravinskyi Eric Hambro Sainbayar Sukhbaatar Roberta Raileanu [ [ [ [ ahavrilla3@gatech.edu (March 7, 2024) Abstract Reinforcement Learning from Human Feedback ( RLHF ) has emerged as a dominant approach for aligning LLM outputs with human preferences. Inspired by the success of RLHF, we study the performance of multiple algorithms that learn from feedback (Expert Iteration, Proximal Policy Optimization ( PPO ), Return-Conditioned RL) on improving LLM reasoning capabilities. We investigate both sparse and dense rewards provided to the LLM both heuristically and via a learned reward model. We additionally start from multiple model sizes and initializations both with and without supervised fine-tuning ( SFT ) data. Overall, we find all algorithms perform comparably, with Expert Iteration performing best in most cases. Surprisingly, we find the sample complexity of Expert Iteration is similar to that of PPO, requiring at most on the order of 10^{6} samples to converge from a pretrained checkpoint. We investigate why this is the case, concluding that during RL training models fail to explore significantly beyond solutions already produced by SFT models. Additionally, we discuss a trade off between maj@1 and pass@96 metric performance during SFT training and how conversely RL training improves both simultaneously. We then conclude by discussing the implications of our findings for RLHF and the future role of RL in LLM fine-tuning. correspondence Alex Havrilla at 1Introduction The reasoning abilities of large language models ( LLMs ) are rapidly improving as measured by their performance on numerous math, science and code benchmarks (Cobbe et al., 2021 ; Hendrycks et al., 2021b ; Sawada et al., 2023 ; Liang et al., 2022 ; Srivastava et al., 2022 ; Rein et al., 2023 ; Mialon et al., 2023 ; Chollet, 2019 ; Mishra et al., 2022 ; Hendrycks et al., 2021a ; Austin et al., 2021 ; Patel et al., 2021 ; Gao et al., 2021 ) . Simultaneously, Reinforcement Learning from Human Feedback (RLHF) (Bai et al., 2022 ; Ziegler et al., 2019 ; Ouyang et al., 2022 ) and instruction fine-tuning (Wei et al., 2021 ; Mishra et al., 2021 ) have made significant progress in aligning LLMs with human preferences. Improvements in model instructability have further increased apparent model capability by making complex behaviors more accessible via instruction prompting. This has led to a number of increasingly sophisticated prompting strategies augmenting LLM reasoning capabilities such as Chain-of-Thought (Wei et al., 2022 ) or Tree-of-Thoughts (Yao et al., 2023 ) . Previous work in reinforcement learning (RL) such as AlphaGo (Silver et al., 2017 ) , AlphaStar (Vinyals et al., 2019 ) , and OpenAI Dota 2 (Berner et al., 2019 ) demonstrate that RL techniques can be used to train neural networks capable of sophisticated planning and reasoning in game environments. Cicero (Bakhtin et al., 2022 ) in particular succeeds in combining an RL trained planning agent with a dialogue fine-tuned LLM to achieve nearly super-human performance in the board game Diplomacy. Given these previous successes and the inherent interactive nature of problem solving, applying RL to LLM reasoning seems a natural next step. In this paper, we study how ideas from RL can be used to improve the reasoning capabilities of LLMs across a variety of reward schemes and model initializations. We begin by comparing the performance of different RL algorithms on reasoning tasks tau defined as a distribution of question answer tuples (Q,A) . The task tau can be extended to define a Markov Decision Process ( MDP ) 4-tuple (mathcal{S},mathcal{A},P_{a},R_{a}) where tokens serve as both actions and accumulated state with deterministic dynamics. By default we use a sparse reward of +1 if the final answer is correct but also experiment with dense rewards matching intermediate steps in a reference solution and rewards synthetically generated using a reward model. We evaluate models with 7B and 13B parameters both starting from supervised fine-tuned (SFT) checkpoints and pre-trained checkpoints. We report four metrics assessing model performance on a task specific test set: 1) maj@1 score computed by greedily sampling once per question, 2) maj@96 score computed by sampling K = 96 times per question and uniformly voting on the final answer, 3) rerank@96 score computed by sampling K = 96 times and choosing the final answer using an Outcome-Based Reward Model ( ORM ), and 4) pass@96 score computed by sampling the model K = 96 times and taking the best result according to the ground truth answer. We find that overall the simplest method, Expert Iteration ( EI ) (Anthony et al., 2017 ) , performs best across all metrics for most reward setups and model initializations. Surprisingly, EI is nearly as sample efficient as more sophisticated algorithms like Proximal Policy Optimization ( PPO ), both requiring only a few thousand samples to converge even when initialized from a pretrained checkpoint. We also observe the gap between pretrained model performance and SFT model performance significantly shrinks ( &lt; 10% gap on GSM8K) after RL fine-tuning, with larger models having a smaller gap. Additionally, previous work identified a tradeoff between test time maj@1 performance and pass@96 performance during supervised fine-tuning (Cobbe et al., 2021 ) , with continued training increasing maj@1 score at the expense of pass@96 score. We identify the limited diversity of the dataset as a core reason for this. We show that RL fine-tuning can improve both metrics simultaneously due to the fact that RL generates its own data during training, resulting in a more diverse set of examples to learn from. We then discuss why EI and return conditioned RL are competitive with PPO, suggesting two principal factors. Firstly, the reasoning tasks we consider have entirely deterministic dynamics: a setting in which direct behavior cloning and return conditioned RL is known to do well (Brandfonbrener et al., 2022 ) . In contrast, PPO often succeeds in environments with a high degree of stochasticity (Bhargava et al., 2023 ) . Second, we identify a lack of sophisticated exploration carried out by models during RL fine-tuning. This limitation significantly impacts any performance or sample complexity advantages PPO may have when fine-tuning the pretrained model. We come to this conclusion from a number of observations, noting in particular quickly saturating pass@96 scores early in RL training. We conclude with a discussion of the impacts of our observations on RLHF and the future of LLM fine-tuning via RL. In summary we make the following contributions: • A comprehensive study of PPO fine-tuning of LLMs on reasoning tasks using different types of rewards, model sizes and initializations. • A comparison to expert iteration and return-conditioned RL from which we find expert iteration reliably attains the best performance and competitive sample complexity across the board. • A discussion of the implications of our findings for RLHF and the future of RL fine-tuning for LLMs, identifying exploration as a major limiting factor. 2Related Work LLM Reasoning: State-of-the-art large language models (OpenAI, 2023 ; Touvron et al., 2023 ; Bai et al., 2022 ; Chowdhery et al., 2022 ) demonstrate increasingly impressive abilties on hard reasoning tasks as studied by a wide range of math, science, and code benchmarks (Cobbe et al., 2021 ; Hendrycks et al., 2021b ; Sawada et al., 2023 ; Liang et al., 2022 ; Srivastava et al., 2022 ; Rein et al., 2023 ; Mialon et al., 2023 ; Chollet, 2019 ; Mishra et al., 2022 ; Hendrycks et al., 2021a ; Austin et al., 2021 ; Patel et al., 2021 ; Gao et al., 2021 ) . Chain of thought ( CoT ) (Wei et al., 2022 ) and related techniques (Chen et al., 2022 ; Yao et al., 2023 ; Besta et al., 2023 ) have emerged as dominant methods siginficantly boosting LLM performance on these types of tasks. CoT methods allow LLMs to defer giving their final answer by first generating a ”chain of thought” involving intermediate computations needed to correctly solve the problem. Another line of work combines base LLM reasoning capabilities with planning and search algorithms to further boost performance on a wide range of tasks (Yao et al., 2023 ; Besta et al., 2023 ; Ye et al., 2022 ; Yao et al., 2022 ; Dohan et al., 2022 ) . Tree of thought (Yao et al., 2023 ) for example combines LLMs with a breadth first search algorithm, relying on the LLM to both propose actions and evaluate state. Other works combine LLMs with tools (Schick et al., 2023 ; Qin et al., 2023 ; Zhou et al., 2023a ) further boosting reasoning capability. Combining GPT-4 with a python code interpreter for generation and self-verification achieves an impressive 84% on the hard MATH benchmark (Hendrycks et al., 2021a ; Zhou et al., 2023a ) . Other works focus on LLMs for mathematical reasoning in natural language (Cobbe et al., 2021 ; Lewkowycz et al., 2022 ; Azerbayev et al., 2023 ; Lightman et al., 2023 ; Patel et al., 2021 ; Zhu et al., 2023 ; Rafailov et al., 2023 ) . Particularly relevant to our study is Cobbe et al. ( 2021 ) which fine-tunes GPT-3 on supervised math word problem ( MWP ) reasoning traces. In addition they train solution verifiers called Outcome Based Reward Models ( ORMs ) which predict the probability of correctly solving a question Q giving a prefix of intermediate steps P_{i}=(S_{1},...,S_{i}) i.e. p(is_correct(A)|Q,P_{i}) where A is a solution with prefix P_{i} . Process based reward models ( PRMs ) (Uesato et al., 2022 ; Lightman et al., 2023 ) can also be trained to instead look at the step-level accuracy of solutions. More recent work (Luo et al., 2023 ) utlizies a PRM distilled from GPT-4 feedback as a reward signal during PPO. RL for LLM fine-tuning: Reinforcement Learning from Human Feedback (RLHF) is perhaps the most well-known application of RL techniques for fine-tuning LLMs. RLHF (Christiano et al., 2017 ; Ziegler et al., 2019 ; Stiennon et al., 2020 ; Ouyang et al., 2022 ; Bai et al., 2022 ; Glaese et al., 2022 ; Peng et al., 2021 ; Ramamurthy et al., 2022 ) most often works by training a reward model to capture human preferences over a task tau . The reward model is then used to score LLM responses to prompts from the task after which policy improvement is performed. PPO is most often used (Ouyang et al., 2022 ; Bai et al., 2022 ) but several recent works including ReST (Gulcehre et al., 2023 ) , Reward-Ranked Fine-tuning (Dong et al., 2023 ) , and AlpacaFarm (Dubois et al., 2023 ) all demonstrate simply fine-tuning on high return responses with the standard cross-entropy loss can attain comparable performance. We broadly refer to this class of algorithms as Expert Iteration. A large body of work studying RL for LLM fine-tuning also exists outside of the RLHF sphere. Work on text games (Yao et al., 2020 ; Ammanabrolu and Riedl, 2019 ) and other interactive textual environments (Zhou et al., 2023b ; Carta et al., 2023 ) seek to ground LLMs via interaction and RL. RL has also been applied to improving model performance on controllable generation and question answering tasks (Lu et al., 2022 ; Liu et al., 2022 ) . Various forms of expert iteration have also been applied to improve LLM reasoning capabilities (Huang et al., 2022 ; Yuan et al., 2023 ; Zelikman et al., 2022 ; Uesato et al., 2022 ) . For example “Scaling Relationship on Learning Mathematical Reasoning with Large Language Models” (Yuan et al., 2023 ) applies a single round of expert iteration across multiple model sizes on GSM8K. They observe sizeable gains in all metrics for smaller models, with gains diminishing for larger models. A related body of work studies RL for code generation (Le et al., 2022 ; Shen et al., 2023 ; Rozière et al., 2023 ) . Shen et al. ( 2023 ) in particular reports a huge increase in StarCoder’s (Li et al., 2023 ) maj@1 performance after a single round of expert iteration, jumping from sim 30% to sim 60%. Despite all the above work, it remains unclear exactly what factors account for the biggest impact during RL fine-tuning due to wide variance in tasks, pretraining data, supervised fine-tuning data, RL algorithm used, and the reward source. Our work conducts a thorough analysis of all these factors to understand exactly how different algorithms compare when applied to improving LLM reasoning capability. As a result we are able to identify key bottlenecks to further LLM improvement via RL and provide a discussion on promising future directions. 3Methods Reasoning as an RL problem We study the performance and sample complexity requirements for various RL algorithms when fine-tuning LLMs on reasoning tasks. We consider Expert Iteration (EI) (Anthony et al., 2017 ) , Proximal Policy Optimization (PPO) (Schulman et al., 2017 ) , and Return-Conditioned RL (RCRL) (Brandfonbrener et al., 2022 ) as representative algorithms from the RL literature. In general, the goal of all RL algorithms is to maximize the expected future return mathbb{E}_{Asimpi(Q),(Q,cdot)intau}R(A) of a student policy pi on task tau . We call the highest return policy the optimal policy pi^{*} . Each of our chosen algorithms goes about finding pi^{*} in a different way. PPO is an example of an online RL algorithm. Online algorithms engage in both an exploration phase and a policy improvement phase which updates pi_{theta} using data generated during the exploration phase. PPO is also an on-policy algorithm which samples model rollouts during exploration from the student policy pi_{theta} being trained. During policy improvement, the student pi_{theta} updates its parameters via gradient descent by directly maximizing for reward with the objective displaystyle J(theta)=mathbb{E}_{t}left[min(frac{pi(a_{t}|s_{t})}{pi_{% textup{old}}(a_{t}|s_{t})}hat{A}_{t},clip(1-epsilon,1+epsilon,frac{pi(a_% {t}|s_{t})}{pi_{textup{old}}(a_{t}|s_{t})})hat{A}_{t})right] where hat{A}_{t} estimates the advantage i.e. difference between Q(s,a) (the expected return after taking action a at state s ) and value V(s) (the expected return at state s ). In practice, for PPO we sample 1024 rollouts at a time with a temperature of 0.7 and N=4 rollouts per question. Training is then run on these samples for K=4 PPO epochs with a batch size of 256. Additionally, we train using LoRA (Hu et al., 2021 ) with r=128 . Training is run for 4000 gradient steps. The best checkpoint is then selected via performance on a validation set. Expert iteration is also online but more off-policy than PPO. An initial expert policy approximation hat{pi}^{*}_{0} is sampled on the entire train set K times per question before any policy improvement. The hat{pi}^{*}_{0} is often constructed using repeated sampling from an initial policy pi_{0} . For example, AlphaZero (Silver et al., 2017 ) and subsequent work (Schick et al., 2023 ) combine pi_{0} with Monte Carlo Tree Search. Sampling hat{pi}^{*}_{0} constructs an initial set of rollouts D_{1} which are then distilled back into a policy pi_{1} via a standard cross-entropy loss: sum_{tauin D}sum_{t=1}^{H}-log(pi_{theta}(a_{t}|s_{t})) . This process can be repeated to construct policy pi_{i} fine-tuned on dataset D_{i}=R_{i}cup D_{i-1} where R_{i} corresponds to exploration done by pi_{i-1} . In our setting we construct an approximation to the optimal policy hat{pi}^{*} by rejection sampling our student policy pi_{theta} . After generating K samples S_{1},...,S_{K} on a question Q we construct D_{1} by filtering all (Q,S_{i}) pairs with return below a threshold T . De-duplication is then performed on the remaining samples. In practice, during the expert iteration exploration phase we sample each question in the train set K=96 times with temperature T=1.0 . To construct the training set we filter out incorrect solutions and duplicates. Importantly, fine-tuning is then done from the pretrained base model with the same hyperparameters as SFT. This is repeated until performance on a validation set saturates. Return Conditioned RL Return conditioned RL algorithms seek to train policies conditioned on both the current state s and desired return R when sampling an action. This is motivated by a desire to learn return conditionable policies which can change depending on the desired return. Best performance can then be sampled by conditioning on the highest possible return. We consider an offline version of this class of algorithms similar to a decision transformer (Chen et al., 2021 ) . A training dataset D is constructed by generating state, action, return tau=((s_{t},a_{t},g_{t}))_{t=1}^{H} trajectories. Training is done by predicting the action given state and return: sum_{tauin D}sum_{t=1}^{H}-log(pi_{theta}(a_{t}|s_{t},g_{t})) . In practice we construct D by sampling solutions S=(S_{1},...,S_{L}) , where each S_{i} is an intermediate step, from our best EI trained policy pi_{textup{EI}} given a question Q . We generate return labels for each step S_{i} by sampling pi_{textup{EI}} K many times from P_{i}=(S_{1},...,S_{i}) . This results in binary labels l_{1},..,l_{K} evaluating the correctness of the generated final answers. S_{i} is then labeled as “[GOOD]” if the average return frac{1}{K}sum_{k=1}^{K}l_{k}geq T and otherwise is labeled as “[BAD]”. Typically we set T=0.5 . We then filter the dataset to ensure a balanced number of correct and incorrect solutions. See Section F in the appendix for more details about the step-label generating process. Outcome Based Reward Modeling Multiple works (Cobbe et al., 2021 ; Uesato et al., 2022 ) train Outcome Based Reward models ORMs as verifiers of candidate solutions to word problems. The ORM can then be used to rerank multiple candidate solutions generated by a student model, significantly boosting performance. Training data for the ORM is generated using a student policy pi by sampling K solutions per question Q in the task dataset. The ORM is trained as a classifier by predicting the probability of reaching the correct final answer p(texttt{is_correct(A)}|Q,P_{i}) from an intermediate sequence of steps P_{i}=(S_{1},...,S_{i}) , P_{i}subseteq A=(S_{1},...,S_{L}) . 4Experiments We conduct our evaluations on GSM8K and SVAMP (Patel et al., 2021 ) : two math word problem benchmarks. In addition on GSM8K we consider two data regimes: first with SFT data and then without SFT data. We evaluate all models using greedy sampling (maj@1) accuracy as well majority vote at 96 samples (maj@96), ORM based reranking at 96 samples (rerank@96), and best of 96 sample (pass@96) accuracy. Unless otherwise specified, test-time sampling is done greedily for maj@1 and with a temperature of 0.7 otherwise. We sample the RCRL models one step/line at a time, conditioning on the “[GOOD]” token. We note while the notion of a “step” is not clearly defined in general, in our case we can simply regard each step as ending with a sentence or newline. All experiments are done using instruction-tuned Llama-2 7B and Llama-2 13B models. maj@1 maj@96 rerank@96 {}^{dagger} pass@96 7B 13B 7B 13B 7B 13B 7B 13B SFT 0.41 0.48 0.47 0.53 0.54 0.68 0.72 0.84 EI {}_{n} 0.48 0.53 0.55 0.59 0.64 0.71 0.8 0.88 ORM EI {}_{n} 0.48 0.53 0.54 0.58 0.65 0.71 0.81 0.87 ORM RCRL 0.45 0.51 0.5 0.56 0.54 0.69 0.73 0.83 Sparse PPO 0.44 0.51 0.49 0.55 0.58 0.67 0.77 0.85 Dense PPO 0.43 0.50 0.47 0.54 0.53 0.65 0.71 0.81 Sparse ORM PPO 0.46 0.51 0.51 0.55 0.59 0.67 0.79 0.83 Dense ORM PPO 0.46 0.51 0.52 0.55 0.59 0.67 0.76 0.83 Llema {}^{*} 0.40 0.62 0.54 0.69 N/A N/A RFT 0.47 0.54 0.58 0.65 N/A N/A WizardMath 0.55 0.64 N/A N/A N/A GPT-3 {}^{**} 0.2 0.31 N/A 0.39 0.55 0.71 NA GPT-4 {}^{***} 0.91 N/A N/A N/A Table 1: Results when initializing from SFT. EI {}_{n} denotes n rounds of expert iteration until convergence with n=2 for 7B and n=2 for 13B. {}^{dagger} Note all reranking is done using an ORM trained with samples from EI {}_{n} . Results from other works are included on the bottom for reference. N/A stands for not available. {}^{*} Llema results reported for 7B/34B sizes without fine-tuning. {}^{**} GPT-3 results reported for 7B/175B sizes. {}^{***} GPT-4 size unknown. # 4.1Results with SFT Initialization Figure 1: Sample complexities of SFT initialized models on GSM8K. EI achieves better performance than PPO with the same order of magnitude of samples. Figure 1: Sample complexities of SFT initialized models on GSM8K. EI achieves better performance than PPO with the same order of magnitude of samples. Figure 2: Accuracy of EI models on GSM8K test vs. number of iterations. Performance seems plateaus for SFT initialized models after two iterations. The pretrained checkpoints converge after four iterations. When given access to SFT data, we first supervise fine-tune Llama-2 models for 4 epochs with a global batch size of 128 and an initial lr of 2e-5 decayed to 2e-7 with a cosine warmup schedule. We call the resulting models SFT . When fine-tuning with PPO we initialize using this checkpoint. In contrast, for both EI and RCRL we generate data with the SFT checkpoint but reset training to start from the pretrained base model. Similarly to Zelikman et al. ( 2022 ) , we find this model resetting is crucial for achieving best performance. Results for both 7B and 13B models are reported in Table 1 . Expert iteration achieves the best performance with competitive sample complexity Surprisingly, we find EI achieves the best performance with a maj@1 accuracy of 0.485 and 0.53 on 7B and 13B models respectively. For both model sizes the best greedy accuracy is achieved after n=2 expert iterations (see Fig. 2 ), after which performance plateaus. In total, EI gives a sizable improvement of around 7% over the SFT baseline. Similar gains can be seen in maj@96, rerank@96, and pass@96 scores with. PPO models underperform EI, with ORM guided PPO giving the biggest improvement of around 5% over the SFT baseline. Again, maj@96, rerank@96, and pass@96 accuracies show similar improvements. Interestingly, despite further training on top of the SFT initialization, PPO models retain competitive rerank@96 and pass@96 scores when compared to regression we see after further supervised fine-tuning. We believe this is due to the relatively more diverse nature of the exploration dataset used to update the model. Finally, RCRL models under-perform EI models despite training on EI generated data with an even balance between ‘[GOOD]’ and ‘[BAD]’ step labels. This matches similar results from Du et al. ( 2023 ) which use only sparse labels for the entire rollout. Further, when sampling the RCRL model unconditionally the model often generates the perfectly valid steps following a ‘[BAD]’ label resulting in a correct final answer. These results suggest RCRL models are not correctly learning what constitutes a ‘[GOOD]’ versus ‘[BAD]’. This suggests RCRL models are unable to usefully incorporate information from partially correct solutions at train time. An ablation (See sec. A of the appendix) on the ratio of positive to negative labels finds a balanced ratio yields the worst performance, with increasing the amount of positive data leading to better results. In Figure 2 we plot the number of model rollouts against model performance in log-scale. PPO models achieve their best accuracies after around 60,000 rollouts while EI models train with an order of magnitude more. However, the resulting train time in both cases is about a day. This is largely due to memory requirements from PPO, resulting in lower rollout throughput and smaller mini-batch sizes at train time. Additionally, in the SFT case we did not experiment with reducing the number of samples from K=96 per question for EI. However, we expect this number can be significantly reduced without impacting performance. For a more thorough investigation of sample complexity requirements, see Figure 6 . Extra guidance from ORMs or dense rewards provides little benefit Overall, the ORM slightly improves PPO performance and negligibly impacts EI performance. For both algorithms it provides an improvement in terms of sample complexity. However, this does not change final performance. See Figures 4 and 4 which plot the performance against number of model rollouts for differnt reward regimes. Giving dense rewards at best provides no extra benefit to performance when given either heuristically or via the ORM. Giving a heuristic dense reward even slightly harms model performance relative to the sparse setting. Recall we give intermediate reward by comparing intermediate model generated steps to the reference solution. This likely encourages more overfit to exact solutions in the train set, limiting solution diversity. Figure 3: maj@1 scores of EI and ORM aided EI models over the course of training. The ORM improves sample efficiency but not performance. Figure 3: maj@1 scores of EI and ORM aided EI models over the course of training. The ORM improves sample efficiency but not performance. Figure 4: maj@1 scores of PPO and ORM guided PPO models over the course of training. As with EI models, the ORM improves sample efficiency but not performance. RL improves maj@1 accuracy without impacting pass@96 performance Looking at the pass@96 accuracies more closely, we see most similarly sized models are within 3% of the best result. This demonstrates with enough sampling, most models are able to solve a very similar range of problems. Further, while the pass@96 accuracy of our best EI model initially seems much higher than the SFT checkpoint, this is only because the SFT checkpoint has undergone much more training on a less diverse dataset. Simply supervised fine-tuning for half as many steps results in a checkpoint with maj@1 = 0.36 but pass@96 = 0.76. This further suggests RL training mostly impacts maj@1 accuracy without significantly improving on a pass@n accuracy which can be achieved with a light amount of supervised fine-tuning. The proximity of pass@96 accuracies among most models is in sharp contrast to the rerank@96 performance. Here we find EI models enjoy around a 5% lead over other models. At first glance this seems contradictory with relatively similar pass@96 performance. However, we believe a non-trivial percentage of this gap is due to overfit of the ORM to the EI model which was used to generate its training data . # 4.2Results with no SFT Initialization maj@1 maj@n rerank@n {}^{dagger} pass@n 7B 13B 7B 13B 7B 13B 7B 13B Prompted 0.05 0.03 0.14 0.18 0.17 0.24 0.22 0.27 EI {}_{n} 0.31 0.4 0.35 0.47 0.39 0.63 0.45 0.83 ORM EI 0.28 0.37 0.33 0.43 0.37 0.59 0.42 0.76 Sparse PPO 0.32 0.41 0.37 0.48 0.41 0.65 0.5 0.83 Sparse ORM PPO 0.29 0.38 0.34 0.44 0.4 0.62 0.49 0.81 Dense ORM PPO 0.29 0.39 0.35 0.45 0.41 0.64 0.5 0.82 Table 2: Results for 7B/13B models when not using SFT initialization on GSM8K. Sparse PPO performs slightly better than EIin this setting. {}^{*} Note all reranking is done using an ORM trained with samples from EI {}_{n} model. maj@1 maj@n rerank@n {}^{dagger} pass@n 7B 13B 7B 13B 7B 13B 7B 13B Prompted 0.06 0.05 0.2 0.25 0.24 0.29 0.3 0.36 EI {}_{n} 0.58 0.69 0.6 0.75 0.62 0.78 0.70 0.93 Sparse PPO 0.44 0.51 0.55 0.66 0.58 0.73 0.72 0.89 Sparse ORM PPO 0.43 0.51 0.52 0.64 0.54 0.71 0.65 0.85 Dense ORM PPO 0.44 0.52 0.51 0.63 0.55 0.73 0.67 0.85 Table 3: Results for 7B/13B models when not using SFT initialization on SVAMP. EI {}_{n} denotes the best EI model after n iterations. EI outperforms PPO. Figure 5: Sample complexities on GSM8K from pretrained initialization. Figure 5: Sample complexities on GSM8K from pretrained initialization. Figure 6: Sample complexities on SVAMP. Surprisingly, EI appears nearly as sample efficient as PPO. We now consider the case when no SFT data is available for training. For questions in both SVAMP and GSM8K we give pretrained models access to a two-shot prompt with samples drawn from the GSM8K validation set. For EI models, we remove these prompts after the first round of exploration, instead relying on the generated SFT data. As in the case with SFT data, we run both algorithms until performance saturates. For PPO this happens after 250 steps on SVAMP and 1000 steps on GSM8K. For EI, this happens after n=5 rounds of exploration and distillation. Results on both datasets are reported in Tables 2 and 3 . EI achieves the best performance overall Even without SFT data, EI achieves the best performance on SVAMP, improving 7B/13B pretrained greedy model accuracies over 50% from 0.06/0.05 to 0.58/0.69%, respectively. PPO performs slightly better than EI on GSM8K, improving from 0.05/0.03 to 0.31/0.4. Both algorithms achieve comparable pass@96 scores across modes sizes, further supporting our observations from the SFT regime that EI mostly improves maj@1 scores relative to PPO. The prompted 13B model on GSM8K even attains 0.83 pass@96 accuracy which is close to the 0.84 pass@96 score achieved by the SFT model, despite having no access to SFT data itself. EI has the same sample complexity as PPO As before we plot the reward versus number of model rollouts for PPO and EI in Figures 6 and 6 . On GSM8K PPO models attain their best maj@1 accuracies after only 30,000 rollouts and on SVAMP even less. Surprisingly, EI models have the same sample complexity as PPO on SVAMP, requiring more samples to converge but also converging to a much higher accuracy. EI still appears to have higher sample complexity on GSM8K, however as noted before this may be due to oversampling each prompt during the exploration phase. To test this, we reduce the number of samples per prompt each round of EI from K=96 to K=4 . The resulting EI models require more iterations to converge but require far less total samples, also converging in accuracy only a few percentage points lower than K=96 samples per prompt. With K=4 rollouts per prompt EI has the same sample complexity as PPO on GSM8K. This is a particularly surprising finding when compared to the performance of EI and PPO on more classical RL problems training a neural network from scratch. Often PPO enjoys far better sample complexity in these settings. One major difference here is the initialization of our student from a pretrained model which imparts a very strong bias on the kind of behaviors and exploration encountered during RL training. Both the extremely small sample complexity and the comparability of EI and PPO in this setting provide more evidence that models are not truly engaging in complex exploration, but instead primarily drawing on what they already know from the pre-training phase. # 4.3Implementation Details It is well known RL training can be quite sensitive to architectural and hyperparameter choices. This is even more so the case for LLM fine-tuning. In this section we ablate and discuss the factors we found most important in our tasks. PPO model architecture and training parameters To save memory we use a joint architecture for the PPO policy and value heads. We found it important to use a relatively large value branch (L=4 transformer layers) and detach the gradients coming from the value branch to the policy trunk. Without detachment we found value gradients interfere with policy gradients, as similarly observed in Stiennon et al. ( 2020 ) , causing instability with a big update to either branch. See Figure 8 which compares maj@1 score of a student with a large value branch and detached value gradients versus the default. Figure 7: maj@1 performance of PPO fine-tuned models against architectural changes. Note, we initialize training from a 7B SFT model with maj@1 = 0.29. Figure 7: maj@1 performance of PPO fine-tuned models against architectural changes. Note, we initialize training from a 7B SFT model with maj@1 = 0.29. Figure 8: Best K of N sampling parameters versus maj@1 score during training. K=4, N=4 yields a fast runtime and best performance. Low rank adaptation (LoRA) (Hu et al., 2021 ) with rank r=128 helped significantly to further stabilize a full layer fine-tuning while still maintaining performance (Sun et al., 2023 ) . A large enough batch size (BS = 256) and a small lr = 1e-6 also helped with stabilization. We additionally experimented with a partial fine-tune of only the top M layers. This saved memory but at the cost of a few percentage points of performance. We also found a non-trivial KL penalty of 0.05 to be critical for preventing model collapse after more than a hundred gradient updates. This is in contrast to Bai et al. ( 2022 ) who do not see a significant need for the KL constraint. We attribute its importance here to the somewhat unnatural distribution of text found in the the reasoning tasks which consist of broken natural language and computations enclosed in &lt;&lt;x+y=z&gt;&gt; tags. For tasks with distributions closer to pure natural language dialogue, such as those considered in Bai et al. ( 2022 ) , the KL constraint seems less necessary. Sampling parameters affect exploration We found the best temperature to use for good exploration during PPO training heavily depends on the initialization. When starting from an SFT checkpoint we choose T = 0.7. However, sampling on a high temperature when starting from the pretrained prompted model often results in collapse. In these cases we choose a low temperature (T = 0.2). Potentially better results for PPO could likely be achieved by annealing the exploration temperature over the course of training. We similarly experimented with the sampling temperature used during exploration in EI, ultimately deciding on T=1.0 to maximize solution diversity without sampling too many degenerate solutions. We also experimented with best K of N (KoN) sampling during PPO training to promote more solution diversity. In this setup the K highest reward samples of N rollouts from a single prompt are kept for training and the rest are discarded. Choosing parameters K ll N prioritize high reward samples and discard low reward ones, resulting in a training distribution more similar to the curated EI dataset. However, one important consideration is the impact of the K/N ratio on training time and sample complexity, with smaller ratios taking proportionally longer. For example, K=1,N=8 takes 8 times as long as the default K=1,N=1. Further, we ultimately found little benefit to small K/N ratios with most configurations yielding decreased performance over K=1,N=1. In practice we found setting K=4, N=4 worked best. See Figure 8 which compares the performance of various choices of K and N. Model size and initialization affect exploration We found both the quality of the student initialization and the size of the student significantly affected the type of exploration engaged in during training. In particular larger models engaged in more diverse exploration while models with worse generalization engaged in less diverse exploration (See Appendix Section B ). This in turn directly impacts model performance when trained on exploration data, with models engaging in more diverse exploration improving more from RL training. maj@1 maj@96 Rerank@96 pass@96 SFT {}^{2} 0.36 0.45 0.53 0.76 SFT {}^{4} 0.41 0.47 0.54 0.72 PPO {}^{2} 0.43 0.48 0.59 0.8 PPO {}^{4} 0.44 0.49 0.58 0.77 Table 4: Results for full supervised fine-tune (SFT {}^{4} ), half supervised fine-tune (SFT {}^{2} ) and their PPO fine-tunes. Fine-tuning for only two epochs gets pass@96 = 0.76. This decreases to 0.72 with two additional epochs of fine-tuning. To further examine the observations about overfitting, we supervise fine-tune a Llama-2-7B model for half as many steps than the SFT model reported in Table 1 . We call the model trained for four epochs SFT {}^{4} and the model trained for two epochs SFT {}^{2} . Despite half the training, SFT {}^{2} has similar Rerank@96 and superior pass@96 scores to SFT {}^{4} with the main difference being the maj@1 accuracies. When sampled K = 96 times on each train prompt, SFT {}^{2} produces on average 3.7 unique correct solutions compared to SFT {}^{4} which produces 2.9 unique correct solutions. We also find SFT {}^{2} benefits significantly more from RL fine-tuning than SFT {}^{4} , jumping from maj@1=0.36 to maj@1=0.43. It’s important to note some of this improvement also happens with continued SFT training, however at the cost to model output diversity and pass@96 performance. We believe RL fine-tuning is less prone to overfitting when compared to static SFT fine-tuning precisely because of the exploration process which generates its own training data. This results in in more diverse solution paths than the SFT training set, ameliorating overfit. This is also in line with recent work that found RLHF to result in better (out-of-distribution) generalization than SFT on summarization and instruction following tasks (Kirk et al., 2023 ) . This benefit can be found both PPO and EI which have almost 10% pass@96 improvement over continued SFT (yet a much smaller pass@96 improvement over a light SFT). To support this hypothesis we plot the solution accuracies and diversities of EI models over each iteration in Figures 10 and 12 , respectively. Figure 12 also shows larger models generate more diverse solutions. 5Discussion and Conclusions Our study resulted in the following findings: 1. All the tested RL algorithms perform similarly on reasoning tasks, with Expert Iteration performing best in most cases. 2. Both EI and PPO converge relatively quickly even without supervised fine-tuning, requiring only sim 60,000 model rollouts. 3. Neither algorithm benefits significantly from ORM guidance or a denser reward. 4. EI and PPO fine-tuning simultaneously improves maj@1 score and pass@n score in contrast with SFT. The improvement of both maj@1 and pass@n performance noted above is due to the ability of online RL algorithms to dynamically grow diverse sets of training examples via synthetic data generation. This allows for longer training/more gradient updates on the same model without adversely impacting output diversity and pass@n scores. In contrast, SFT training occurs on a static dataset. This limits how much training can occur before maj@1 overfit occurs and output diversity suffers. However, RL training does not significantly improve pass@n score beyond what can be achieved with light supervised fine-tuning. This suggests even with RL training our best models are not discovering solutions beyond what can be discovered with (light) supervised fine-tuning given the same rollout budget. This observation, taken together with the fast convergence of both online algorithms and the low-impact of ORM guidance and dense rewards, suggests models are not engaging in a significant amount of exploration beyond pretraining/SFT data. Regardless of the type of algorithm used or the quality of the reward, all student models engage in similar exploration, resulting in similar performance. Crucial in our setting is the usage of a pretrained model imparting a strong exploration prior. Without such a prior, exploration in a high-dimensional textual action space would be impossible. However, this prior also appears to constrain the exploration engaged in at the beginning of training, with additional SFT training only making things worse. We view the discovery of new techniques encouraging complex, rich exploration of reasoning problems as fundamental to progress in LLM reasoning capability. More sophisticted prompting strategies such as Tree of Thought (Yao et al., 2023 ) and combining LLM generative abilities with evolutionary algorithms (Lehman et al., 2022 ) have already begun to make progress in this direction. In addition to the limited exploration noted above, we also note reasoning environments are entirely deterministic. This is a setting in which EI and RCRL algorithms are already known to work well theoretically (Brandfonbrener et al., 2022 ) . PPO enjoys more advantage in environemnts with a high degree of stochasticity. We also note prior work in RLHF finds PPO outperforms EI type approaches in human preference satisfaction and instruction following (Gulcehre et al., 2023 ; Dubois et al., 2023 ; Kirk et al., 2023 ) . Importantly, in our setting we always have a reliable ground truth reward to optimize. However, in RLHF, models must optimize against an unreliable reward model, often resulting in over-optimization (Gao et al., 2022 ) . The relatively superior performance of PPO over EI on RLHF tasks versus reasoning tasks suggests PPO better mitigates such over-optimization. This is not too surprising since PPO training penalizes student models diverging from the initial policy via both its clipped objective and additional KL-constraint. In contrast, EI training has no such protection built in. References Ammanabrolu and Riedl (2019) Prithviraj Ammanabrolu and Mark Riedl. Playing text-adventure games with graph-based deep reinforcement learning. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 3557–3565, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. 10.18653/v1/N19-1358 . URL https://aclanthology.org/N19-1358 . Anthony et al. (2017) Thomas W. Anthony, Zheng Tian, and David Barber. Thinking fast and slow with deep learning and tree search. In Neural Information Processing Systems , 2017. URL https://api.semanticscholar.org/CorpusID:19449905 . Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. Program synthesis with large language models. ArXiv , abs/2108.07732, 2021. URL https://api.semanticscholar.org/CorpusID:237142385 . Azerbayev et al. (2023) Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. Llemma: An open language model for mathematics. ArXiv , abs/2310.10631, 2023. URL https://api.semanticscholar.org/CorpusID:264172303 . Bai et al. (2022) Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, John Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, E Perez, Jamie Kerr, Jared Mueller, Jeff Ladish, J Landau, Kamal Ndousse, Kamile Lukovsiūtė, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noem’i Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, T. J. Henighan, Tristan Hume, Sam Bowman, Zac Hatfield-Dodds, Benjamin Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom B. Brown, and Jared Kaplan. Constitutional ai: Harmlessness from ai feedback. ArXiv , abs/2212.08073, 2022. URL https://api.semanticscholar.org/CorpusID:254823489 . Bakhtin et al. (2022) Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob, Mojtaba Komeili, Karthik Konath, Minae Kwon, Adam Lerer, Mike Lewis, Alexander H. Miller, Sasha Mitts, Adithya Renduchintala, Stephen Roller, Dirk Rowe, Weiyan Shi, Joe Spisak, Alexander Wei, David Wu, Hugh Zhang, and Markus Zijlstra. Human-level play in the game of ¡i¿diplomacy¡/i¿ by combining language models with strategic reasoning. Science , 378(6624):1067–1074, 2022. 10.1126/science.ade9097 . URL https://www.science.org/doi/abs/10.1126/science.ade9097 . Berner et al. (2019) Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemyslaw Debiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Christopher Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub W. Pachocki, Michael Petrov, Henrique Pondé de Oliveira Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan Zhang. Dota 2 with large scale deep reinforcement learning. ArXiv , abs/1912.06680, 2019. URL https://api.semanticscholar.org/CorpusID:209376771 . Besta et al. (2023) Maciej Besta, Nils Blach, Alevs Kubivcek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. Graph of thoughts: Solving elaborate problems with large language models. ArXiv , abs/2308.09687, 2023. URL https://api.semanticscholar.org/CorpusID:261030303 . Bhargava et al. (2023) Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani, and Amy Zhang. Sequence modeling is a robust contender for offline reinforcement learning. ArXiv , abs/2305.14550, 2023. URL https://api.semanticscholar.org/CorpusID:258866105 . Brandfonbrener et al. (2022) David Brandfonbrener, Alberto Bietti, Jacob Buckman, Romain Laroche, and Joan Bruna. When does return-conditioned supervised learning work for offline reinforcement learning? ArXiv , abs/2206.01079, 2022. URL https://api.semanticscholar.org/CorpusID:249282285 . Carta et al. (2023) Thomas Carta, Clément Romac, Thomas Wolf, Sylvain Lamprier, Olivier Sigaud, and Pierre-Yves Oudeyer. Grounding large language models in interactive environments with online reinforcement learning. ArXiv , abs/2302.02662, 2023. URL https://api.semanticscholar.org/CorpusID:256615643 . Chen et al. (2021) Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, P. Abbeel, A. Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. In Neural Information Processing Systems , 2021. URL https://api.semanticscholar.org/CorpusID:235294299 . Chen et al. (2022) Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. ArXiv , abs/2211.12588, 2022. Chollet (2019) François Chollet. On the measure of intelligence. ArXiv , abs/1911.01547, 2019. URL https://api.semanticscholar.org/CorpusID:207870692 . Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier García, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Díaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways. J. Mach. Learn. Res. , 24:240:1–240:113, 2022. URL https://api.semanticscholar.org/CorpusID:247951931 . Christiano et al. (2017) Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. Advances in neural information processing systems , 30, 2017. Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. ArXiv , abs/2110.14168, 2021. URL https://api.semanticscholar.org/CorpusID:239998651 . Dohan et al. (2022) David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A. Saurous, Jascha Narain Sohl-Dickstein, Kevin Murphy, and Charles Sutton. Language model cascades. ArXiv , abs/2207.10342, 2022. Dong et al. (2023) Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng Zhang, Kashun Shum, and T. Zhang. Raft: Reward ranked finetuning for generative foundation model alignment. ArXiv , abs/2304.06767, 2023. URL https://api.semanticscholar.org/CorpusID:258170300 . Du et al. (2023) Yuqing Du, Alexander Havrilla, Sainbayar Sukhbaatar, Pieter Abbeel, and Roberta Raileanu. A study on improving reasoning in language models. In I Can’t Believe It’s Not Better Workshop: Failure Modes in the Age of Foundation Models , 2023. URL https://openreview.net/forum?id=tCZFmDyPFm . Dubois et al. (2023) Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto. Alpacafarm: A simulation framework for methods that learn from human feedback. ArXiv , abs/2305.14387, 2023. URL https://api.semanticscholar.org/CorpusID:258865545 . Gao et al. (2021) Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. A framework for few-shot language model evaluation, September 2021. URL https://doi.org/10.5281/zenodo.5371628 . Gao et al. (2022) Leo Gao, John Schulman, and Jacob Hilton. Scaling laws for reward model overoptimization. In International Conference on Machine Learning , 2022. URL https://api.semanticscholar.org/CorpusID:252992904 . Glaese et al. (2022) Amelia Glaese, Nathan McAleese, Maja Trkebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, A. See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Sovna Mokr’a, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William S. Isaac, John F. J. Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. Improving alignment of dialogue agents via targeted human judgements. ArXiv , abs/2209.14375, 2022. URL https://api.semanticscholar.org/CorpusID:252596089 . Gulcehre et al. (2023) Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alexa Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, A. Doucet, Orhan Firat, and Nando de Freitas. Reinforced self-training (rest) for language modeling. ArXiv , abs/2308.08998, 2023. URL https://api.semanticscholar.org/CorpusID:261031028 . Hendrycks et al. (2021a) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset, 2021a. Hendrycks et al. (2021b) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. ArXiv , abs/2103.03874, 2021b. URL https://api.semanticscholar.org/CorpusID:232134851 . Hu et al. (2021) J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. ArXiv , abs/2106.09685, 2021. URL https://api.semanticscholar.org/CorpusID:235458009 . Huang et al. (2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. Large language models can self-improve. ArXiv , abs/2210.11610, 2022. Jiang et al. (2020) Minqi Jiang, Edward Grefenstette, and Tim Rocktäschel. Prioritized level replay. In International Conference on Machine Learning , 2020. URL https://api.semanticscholar.org/CorpusID:222208809 . Kirk et al. (2023) Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward Grefenstette, and Roberta Raileanu. Understanding the effects of rlhf on llm generalisation and diversity. arXiv preprint arXiv:2310.06452 , 2023. Le et al. (2022) Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven C. H. Hoi. Coderl: Mastering code generation through pretrained models and deep reinforcement learning. ArXiv , abs/2207.01780, 2022. URL https://api.semanticscholar.org/CorpusID:250280117 . Lehman et al. (2022) Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, and Kenneth O. Stanley. Evolution through large models. 2022. URL https://api.semanticscholar.org/CorpusID:249848020 . Lewkowycz et al. (2022) Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Solving quantitative reasoning problems with language models. ArXiv , abs/2206.14858, 2022. URL https://api.semanticscholar.org/CorpusID:250144408 . Li et al. (2023) Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nourhan Fahmy, Urvashi Bhattacharyya, W. Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, Alexander Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean M. Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the source be with you! ArXiv , abs/2305.06161, 2023. URL https://api.semanticscholar.org/CorpusID:258588247 . Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, E. Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel J. Orr, Lucia Zheng, Mert Yüksekgönül, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chatterji, O. Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. Holistic evaluation of language models. ArXiv , abs/2211.09110, 2022. URL https://api.semanticscholar.org/CorpusID:263423935 . Lightman et al. (2023) Hunter Lightman, Vineet Kosaraju, Yura Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. ArXiv , abs/2305.20050, 2023. URL https://api.semanticscholar.org/CorpusID:258987659 . Liu et al. (2022) Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, and Yejin Choi. Rainier: Reinforced knowledge introspector for commonsense question answering. ArXiv , abs/2210.03078, 2022. URL https://api.semanticscholar.org/CorpusID:252735191 . Lu et al. (2022) Ximing Lu, Sean Welleck, Liwei Jiang, Jack Hessel, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, and Yejin Choi. Quark: Controllable text generation with reinforced unlearning. ArXiv , abs/2205.13636, 2022. URL https://api.semanticscholar.org/CorpusID:249152301 . Luo et al. (2023) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-Guang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. ArXiv , abs/2308.09583, 2023. URL https://api.semanticscholar.org/CorpusID:261030818 . Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas Wolf, Yann André LeCun, and Thomas Scialom. Gaia: a benchmark for general ai assistants. 2023. URL https://api.semanticscholar.org/CorpusID:265351664 . Mishra et al. (2021) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization via natural language crowdsourcing instructions. In Annual Meeting of the Association for Computational Linguistics , 2021. URL https://api.semanticscholar.org/CorpusID:237421373 . Mishra et al. (2022) Swaroop Mishra, Pan Lu, and A. Kalyan. Lila: A unified benchmark for mathematical reasoning. 2022. URL https://api.semanticscholar.org/CorpusID:257405677 . OpenAI (2023) OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023. URL https://api.semanticscholar.org/CorpusID:257532815 . Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, and Ryan J. Lowe. Training language models to follow instructions with human feedback. ArXiv , abs/2203.02155, 2022. URL https://api.semanticscholar.org/CorpusID:246426909 . Patel et al. (2021) Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are nlp models really able to solve simple math word problems?, 2021. Peng et al. (2021) Xiangyu Peng, Siyan Li, Sarah Wiegreffe, and Mark Riedl. Inferring the reader: Guiding automated story generation with commonsense reasoning, 2021. Qin et al. (2023) Yujia Qin, Shi Liang, Yining Ye, Kunlun Zhu, Lan Yan, Ya-Ting Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Marc H. Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis. ArXiv , abs/2307.16789, 2023. URL https://api.semanticscholar.org/CorpusID:260334759 . Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model. ArXiv , abs/2305.18290, 2023. URL https://api.semanticscholar.org/CorpusID:258959321 . Ramamurthy et al. (2022) Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kianté Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, and Yejin Choi. Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization. ArXiv , abs/2210.01241, 2022. URL https://api.semanticscholar.org/CorpusID:252693405 . Rein et al. (2023) David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&amp;a benchmark. ArXiv , abs/2311.12022, 2023. URL https://api.semanticscholar.org/CorpusID:265295009 . Rozière et al. (2023) Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve. Code llama: Open foundation models for code, 2023. Salimans and Chen (2018) Tim Salimans and Richard J. Chen. Learning montezuma’s revenge from a single demonstration. ArXiv , abs/1812.03381, 2018. URL https://api.semanticscholar.org/CorpusID:54463584 . Sawada et al. (2023) Tomohiro Sawada, Daniel Paleka, Alex Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J. Nay, Kshitij Gupta, and Aran Komatsuzaki. Arb: Advanced reasoning benchmark for large language models. ArXiv , abs/2307.13692, 2023. URL https://api.semanticscholar.org/CorpusID:260155126 . Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. ArXiv , abs/2302.04761, 2023. URL https://api.semanticscholar.org/CorpusID:256697342 . Schulman et al. (2017) John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. ArXiv , abs/1707.06347, 2017. URL https://api.semanticscholar.org/CorpusID:28695052 . Sennrich et al. (2015) Rico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine translation models with monolingual data. ArXiv , abs/1511.06709, 2015. URL https://api.semanticscholar.org/CorpusID:15600925 . Shen et al. (2023) Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan Zeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, Yuenan Guo, and Qianxiang Wang. Pangu-coder2: Boosting large language models for code with ranking feedback. ArXiv , abs/2307.14936, 2023. URL https://api.semanticscholar.org/CorpusID:260202985 . Silver et al. (2017) David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, L. Sifre, Dharshan Kumaran, Thore Graepel, Timothy P. Lillicrap, Karen Simonyan, and Demis Hassabis. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. ArXiv , abs/1712.01815, 2017. URL https://api.semanticscholar.org/CorpusID:33081038 . Srivastava et al. (2022) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Annasaheb Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmuller, Andrew M. Dai, Andrew La, Andrew Kyle Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakacs, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bartlomiej Bojanowski, Batuhan Ozyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Stephen Howald, Bryan Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, C’esar Ferri Ram’irez, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt, Christopher D. Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Daniel H Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Mosegu’i Gonz’alez, Danielle R. Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth P. Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan A. Chi, Ethan Dyer, Ethan J. Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Mart’inez-Plumed, Francesca Happ’e, François Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germán Kruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Wang, Gonzalo Jaimovitch-L’opez, Gregor Betz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Shevlin, Hinrich Schutze, Hiromu Yakura, Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, John Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B. Simon, James Koppel, James Zheng, James Zou, Jan Koco’n, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jascha Narain Sohl-Dickstein, Jason Phang, Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Oluwadara Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Jane W Waweru, John Burden, John Miller, John U. Balis, Jonathan Batchelder, Jonathan Berant, Jorg Frohberg, Jos Rozen, José Hernández-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja Markert, Kaustubh D. Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe Morency, Luca Moschella, Luca Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros Col’on, Luke Metz, Lutfi Kerem cSenel, Maarten Bosma, Maarten Sap, Maartje ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ram’irez Quintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L. Leavitt, Matthias Hagen, M’aty’as Schubert, Medina Baitemirova, Melody Arnaud, Melvin Andrew McElrath, Michael A. Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube, Michal Swkedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Monica Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, T MukundVarma, Nanyun Peng, Nathan A. Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron, Nicholas Roberts, Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter Chang, Peter Eckersley, Phu Mon Htut, Pi-Bei Hwang, P. Milkowski, Piyush S. Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel Habacker, Ramon Risco, Raphael Milliere, Rhythm Garg, Richard Barnes, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan Lebras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel R. Bowman, Samuel S. Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi S. Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima Debnath, Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsunori Hashimoto, Te-Lin Wu, Theo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Venkatesh Ramasesh, Vinay Uday Prabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yu Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zi Fu Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. 2022. URL https://api.semanticscholar.org/CorpusID:263625818 . Stiennon et al. (2020) Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan J. Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul Christiano. Learning to summarize from human feedback. ArXiv , abs/2009.01325, 2020. URL https://api.semanticscholar.org/CorpusID:221665105 . Sun et al. (2023) Simeng Sun, Dhawal Gupta, and Mohit Iyyer. Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of rlhf. ArXiv , abs/2309.09055, 2023. URL https://api.semanticscholar.org/CorpusID:261884455 . Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023. Uesato et al. (2022) Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, L. Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins. Solving math word problems with process- and outcome-based feedback. ArXiv , abs/2211.14275, 2022. URL https://api.semanticscholar.org/CorpusID:254017497 . Vinyals et al. (2019) Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, L. Sifre, Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander Sasha Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy, Tom Le Paine, Caglar Gulcehre, Ziyun Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy P. Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps, and David Silver. Grandmaster level in starcraft ii using multi-agent reinforcement learning. Nature , 575:350 – 354, 2019. URL https://api.semanticscholar.org/CorpusID:204972004 . Wei et al. (2021) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners. ArXiv , abs/2109.01652, 2021. URL https://api.semanticscholar.org/CorpusID:237416585 . Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. ArXiv , abs/2201.11903, 2022. Yao et al. (2020) Shunyu Yao, Rohan Rao, Matthew J. Hausknecht, and Karthik Narasimhan. Keep calm and explore: Language models for action generation in text-based games. ArXiv , abs/2010.02903, 2020. URL https://api.semanticscholar.org/CorpusID:222142129 . Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. ArXiv , abs/2210.03629, 2022. URL https://api.semanticscholar.org/CorpusID:252762395 . Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. ArXiv , abs/2305.10601, 2023. URL https://api.semanticscholar.org/CorpusID:258762525 . Ye et al. (2022) Anbang Ye, Christopher Cui, Taiwei Shi, and Mark O. Riedl. Neural story planning. ArXiv , abs/2212.08718, 2022. URL https://api.semanticscholar.org/CorpusID:254854533 . Yuan et al. (2023) Zheng Yuan, Hongyi Yuan, Cheng Li, Guanting Dong, Chuanqi Tan, and Chang Zhou. Scaling relationship on learning mathematical reasoning with large language models. ArXiv , abs/2308.01825, 2023. URL https://api.semanticscholar.org/CorpusID:260438790 . Zelikman et al. (2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. Star: Bootstrapping reasoning with reasoning, 2022. Zhou et al. (2023a) Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification. ArXiv , abs/2308.07921, 2023a. URL https://api.semanticscholar.org/CorpusID:260900008 . Zhou et al. (2023b) Wei Zhou, Xiangyu Peng, and Mark O. Riedl. Dialogue shaping: Empowering agents through npc interaction. ArXiv , abs/2307.15833, 2023b. URL https://api.semanticscholar.org/CorpusID:260333931 . Zhu et al. (2023) Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang, Yongfeng Huang, Ruyi Gan, Jiaxing Zhang, and Yujiu Yang. Solving math word problems via cooperative reasoning induced language models. Association for Computational Linguistics, 2023. 10.18653/v1/2023.acl-long.245 . URL https://doi.org/10.18653%2Fv1%2F2023.acl-long.245 . Ziegler et al. (2019) Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593 , 2019. Appendix ARCRL Label Balance We also experiment with different proportions of ‘[GOOD]’ and ‘[BAD]’ labels in RCRL training data. This is motivated by a desire to make better use of abundant negative data, which is much easier to generate than its positive counterpart. Better teaching the student what not to do with this data would ideally increase the number of valid solutions. Recall by default we balance the number of positive and negative samples. We conduct experiments on LLama-2 7 GSM8K without any SFT data. We apply only one round of Expert Iteration ( K=1 per question), producing a student model we refer to as EI-minimal . Note, in this setting we only provide ‘[GOOD]’ and ‘[BAD]’ labels for entire solutions, rather than providing labels at the step level. Results are reported in 5 . positive:negative ratio GSM8K (maj@1) EI-minimal - 0.17 100:1 0.18 RCRL 10:1 0.18 1:1 0.15 Table 5: RCRL without SFT, using different proportions of positive and negative samples. As we increase the proportion of negative samples, performance generally decreases. At best, we only see very marginal gains using RCRL . Note: EI-minimal refers to running EI for one iteration, with K=1 per question. We find we achieve best performance when the amount of positive training data greatly outweighs the amount of negative data. In these cases, our RCRL models’ maj@1 score slightly exceeds the maj@1 score of the data generating EI-minimal model. Yet, when we balance the amount of positive and negative training data, we find performance is degraded. This suggests our 7B student doesn’t effectively learn from the provided negative demonstrations. We suspect either a larger model or an easier task would give better results. Appendix BEI Improvement across Iterations Figures 10 and 10 plot the maj@1 score of models on versus rounds of expert iteration. On both datasets the score is monotonically increasing until convergence after at most four rounds. Models initialized from an SFT checkpoint converge faster than their pretrained counterparts. Each round of expert iteration samples K*texttt{num_train} rollouts, with the longest running training loop generate at most 5*4*7000approx 10^{6} samples. Figure 9: Accuracy of EI models on GSM8K test vs. number of iterations. EI scratch models have use no SFT initialization. Figure 9: Accuracy of EI models on GSM8K test vs. number of iterations. EI scratch models have use no SFT initialization. Figure 10: Accuracy of EI models on GSM8K test vs. number of iterations. K=4 samples per prompt are used to construct a fine-tuning dataset for the next round. Figure 11: Diversity of GSM8K model output over rounds of EI. (No SFT) Figures 11 and 12 report the diversity of solutions across rounds of expert iteration as measured by two separate metrics for solution uniqueness. exact diversity checks for equality between two solutions using exact string match. trace diversity checks for equality between two solutions by first extracting the trace of a solution as the sequence of intermediate calculations used to get to the final answer. An exact match is then performed on this trace representation. Figure 12: Diversity of SVAMP model output over rounds of EI. K=96 samples are used per prompt. positive diversity measures diversity in the subset of solutions with a correct final answer. Solution diversity increases then decreases over training Overall both measures of solution diversity increase for both model sizes over the first two rounds of expert iteration. After the first two rounds both trace diversity appears to plateau and in some cases slightly decrease. Exact diversity continues to increase for 13B, but not at the same rate as during the first two rounds. The largest increases in solution diversity over the first two rounds also match when the largest gains in maj@1 performance occur. This lends evidence to the intuition that a high-performing student will be able to generate many correct but unique solutionst to the same problem. Further, we see during later rounds of expert iteration that while maj@1 score improves slightly, diversity suffers. This provides further evidence that training is begining to overfit to maj@1 score, in the process reducing both pass@n and solution diversity. We see the same behavior Figure 13: gsm8k sft diversity Larger models generate more diverse solutions The above figures also demonstrate the 13B model produces signifcantly more diverse outputs than the 7B model. This is true during every round of fine-tuning, with the gap getting larger as more training is done. Interestingly, the 13B model appears to produce an exactly unique solution with every sampling after 4 rounds of expert iteration. However, its trace diversity peaks after two rounds, indicating 13B tends to introduce semantic diversity without changing the underlying computational structure of a solution. Appendix CSample Complexities In this section we plot all sample complexities on benchmarks accompanying the results in Section 4 . Figures 15 and 15 report results on GSM8K without supervised fine-tuning. Figures 17 and 17 report results on SVAMP. Figure 14: Sample complexity of default versus ORM guided EI students on GSM8K (no SFT). The ORM improves sample complexity initially but ultimately underperforms using only the ground truth. Figure 14: Sample complexity of default versus ORM guided EI students on GSM8K (no SFT). The ORM improves sample complexity initially but ultimately underperforms using only the ground truth. Figure 15: Sample complexity of default versus ORM guided PPO students on GSM8K (no SFT). Similarly to as in EI, the ORM improves maj@1 score over using only ground truth rewards but eventually underperforms. Figure 16: Sample complexity of default versus ORM guided EI students on SVAMP. Figure 16: Sample complexity of default versus ORM guided EI students on SVAMP. Figure 17: Sample complexity of default versus ORM guided PPO students on SVAMP. As in the SFT case, using an ORM to guide EI and PPO on prompted GSM8K models does somewhat reduce sample complexity but does not improve best performance (if anything the ORM reward slightly hurts converged maj@1 score). We see the same story when providing a dense ORM reward, further decreasing sample comlexity but at the cost of final converged performance. Our best results still come from using only the ground truth score. We suspect the performance degredation introduced by the ORM reward could be alleviated with a larger reward model. However, we do not believe using a larger model would improve over just the ground truth reward. Similar results are seen for SVAMP. Appendix DCurriculum Learning for RL Figure 18: maj@1 scores for Prioritized Level Replay (PLR) and Backtracking techniques compared to default PPO and SFT. In addition to vanilla PPO we experiment with backtracking (Salimans and Chen, 2018 ) and Prioritized Level Replay ( PLR ) (Jiang et al., 2020 ) as algorithms from the curriculum learning literature. Such algorithms aim to construct a “curriculum” of subproblems, with the model ideally learning to generalize from easier subproblems to harder subproblems. Backtracking in particular is a natural choice as it relies on using high-quality supervised trajectories to improve exploration of the solution space. This is done by sampling the student policy pi on the partially complete solution (Q,P_{i}) where P_{i} is a sequence of intermediate ground truth steps (S_{1},...,S_{i}) . The algorithm proceeds by setting an initial threshold tau_{0}in(0,1) which represents how far back from the final answer to initialize partial solutions. By default we use tau_{0}=0.9 . Then, for each problem Q which can be solved from P_{i} , we remove the last step S_{i} and condition on P_{i-1} the next time Q is sampled. PLR does not rely on access to SFT data, instead heuristically prioritizing problems with high “learning potential” estimated by the average absolute advantage. Prioritizing problems with this potential allows the model to focus on problems that are neither too easy nor too hard, making efficient use of its exploration budget. We initialize the student using a supervised fine-tuned LLama-2 7B on GSM8K. Results are reported in Figure 19 . Figure 19: maj@1 scores on GSM8K for Prioritized Level Replay (PLR) and Backtracking techniques compared to default PPO and SFT. Overall we find neither method exceeds the performance of default PPO. We hypothesize this is due to the limited exploration the model engages in from the start, due to both pretraining and supervised fine-tuning. We speculate better results might be achieved on a harder dataset with more intermediate steps, particularly when using backtracking. Appendix EData augmentation We additionally experimented with generating synthetic (Q,A) training pairs via an approach inspired by backtranslation (Sennrich et al., 2015 ) . We assume access to a supervised fine-tuning dataset mathcal{D} of (Q,A) pairs and train a Qto A model M_{Qto A} as our usual student model. We call this model the verifier. We can also utilize mathcal{D} to train models of the form M_{Ato Q} and M_{Ato A} which map answers to questions and answers to answers respectively. We train M_{Ato Q} simply by fine-tuning the pretrained model M to predict p(A|Q) where (Q,A)simmathcal{D} . We call the combination of M_{Ato A} and M_{Ato Q} the generator. We construct a train set for M_{Ato A} as follows: For each A in (Q,A)inmathcal{D} we randomly sample three other answers A_{1},A_{2},A_{3} from mathcal{D} which act as a conditional prompt. We then train M_{Ato A} by minimizing p(A|A_{1},A_{2},A_{3}) . We sample M_{Ato A} on each ground truth answer Ainmathcal{D} K=8 times, constructing a synthetic dataset of answers mathcal{A} . We then use our backwards model M_{Ato Q} to produce questions for each of the synthetic answers Ainmathcal{A} . This forms a synthetic (Q,A) dataset mathcal{D}_{textup{synth}} . Finally, for each synthetic (Q,A) pair, we sample our student model M_{Qto A} K=20 times for each question and check whether the student model’s final answer agrees with the “intended” final answer. We refer to the percentage of student generated solutions recovering the intended final answer as the score for a synthetic (Q,A) pair. We plot the distribution of scores in Figure 20 . Figure 20: Scores of synthetically backwards generated (Q,A) pairs. Note: the score refers to the percentage of times the forward student model M_{Qto A} recovers the intended final answer. We see that the majority of synthetic pairs, over 50,000, never have their solutions recovered by the student M_{Qto A} . This is either because a) the student is too weak to solve the question or b) the question is impossible to solve. Either way, we likely do not want to include these new training data for the student. Similarly, we likely do not want to include questions which are always solved by the student, i.e. those with score = 1, as they are too easy. Additionally, we should be wary of questions which have a small score in the range (0,epsilon) . We expect many questions will have been solved incorrectly but still arriving at the correct final answer. We should exclude such problems from our training dataset. We expect the highest quality data (Q,A) to have a score in the neighborhood (frac{1}{2}-tau,frac{1}{2}+tau) . These questions should be not too hard but not too easy for our student. Figure 6 shows the performance of student models fine-tuned on a combination of ground truth data and synthetically generated data with scores in the range (frac{1}{2}-tau,frac{1}{2}+tau) . All models are trained for five epochs with an initial lr = 2e-5 cosine decayed to 2e-7. Llama-2 7B is used as the pretrained base model. maj@1 tau=0.1 0.38 tau=0.2 0.36 tau=0.3 0.34 SFT 0.41 Table 6: Performance of models training with various amounts of synthetic data vs. the SFT baseline. Note: tau represents the size of the neighborhood of scores around frac{1}{2} that are not filtered out. Unfortunately, it seems introducing any amount of synthetically generated data degrades performance. When manually inspecting the synthetically generated (Q,A) pairs it becomes clear why. There is an extremely high number of false positives. Consider the following example of a synthetic pair shown in Table E : Question ”A school of 100 musicians goes on a skiing trip. 40% are beginners, 30% are intermediate, and 50% are advanced. How many people went on the skiing trip?” Answer ”There are 100 * 0.4 = 40 beginner skiiers. There are 100 * 0.3 = 30 intermediate skiiers. There are 100 * 0.5 = 50 advanced skiiers. Therefore there are 40 + 30 + 50 = 120 skiiers total.” This is an example of a low-quality sample we do not want in our training data. Ideally, such a sample would have a score of 0 since the technically correct answer is 100, not 120. However, the SFT M_{Qto A} student we use to construct a score for each (Q,A) sample computes the final answer as 120 a staggering 47% of the time. The verifier makes the exactly the same mistakes the M_{Ato A} model made when constructing the question, likely because they were trained on similar distributions. We suspect using a larger model more capable of detecting these sort of trivial non-solutions would do substantially better at generating backwards synthetic data. Similarly, employing separate models as the generator and verifier may reduce the probability of both making the same mistakes, improving the reliability of the score for each pair. We leave this as future work. Appendix FRCRL Step-label Generating Process Another natural candidate which could be used to identify mistakes at each step is a Process Based Reward Model (PRM) (Lightman et al., 2023 ) . A PRM estimates the probability of correctness of a step S_{i} , p(S_{i}texttt{ correct}|Q,S_{1},S_{2},...,S_{i}) independently of its impact on the final answer. However, this would be expensive, requiring collecting human annotated samples. Instead, we propose to approximate the optimal value function V^{*} of the reasoning task. V^{*} corresponds to the value function of the optimal policy which is able to successfully solve the reasoning task from any logically valid intermediate state S_{j} . Such an optimal value function would have V^{*}(Q,S_{1},...,S_{i})=1 for a solution prefix with no mistakes, and V^{*}(Q,S_{1},...,S_{i})=0 if the prefix already contains a mistake which will result in an incorrect final answer. Note however, V^{*} does not exactly correspond to a PRM. This is because a partial solution S_{1},...,S_{i} with a mistake at step jneq i and valid terminal step S_{i} will have V^{*}(Q,S_{1},...,S_{i})=0 and PRM(Q,S_{1},...,S_{i})=1 . To make this distinction clear, we call models we train to directly approximate V^{*} stepwise ORMs or SORMs . === 用中文描述这篇论文解决了什么问题？</div><div class="divider" data-v-f19fca7f></div><p class="review-content" data-v-f19fca7f><span class="icon" data-v-f19fca7f>answer:</span>本文研究了通过强化学习（RL）提高大型语言模型（LLM）推理能力的方法。具体来说，研究了多种算法（包括专家迭代、邻近策略优化（PPO）、条件返回强化学习）在多种奖励方案和模型初始状态下提升LLM推理能力的性能。研究表明，在大多数情况下，专家迭代在各项性能指标上实现了最佳性能，并且与更复杂的算法相比具有可比的样本复杂性。此外，通过强化学习微调的模型能够同时提高准确率和多样性评分，这与仅使用监督微调的模型不同。这些发现为未来使用RL来优化LLM提供了见解。</p></div></div><div class="poem-container" data-v-bf4c880b data-v-f19fca7f><div class="review" data-v-f19fca7f><div class="review-title" data-v-f19fca7f><span class="icon" data-v-f19fca7f>question:</span>Можешь рассказать как влияет КТ на человеческий организм? Что с ним происходит во время якобы безопасного излучения?</div><div class="divider" data-v-f19fca7f></div><p class="review-content" data-v-f19fca7f><span class="icon" data-v-f19fca7f>answer:</span>Компьютерная томография (КТ) является диагностическим методом, который использует рентгеновское излучение для создания подробных трехмерных изображений внутренних органов, тканей и костей человеческого тела. Процедура КТ может быть полезна для обнаружения и оценки различных состояний и заболеваний, таких как опухоли, травмы, инфекции и другие патологии. Влияние рентгеновского излучения на человеческий организм во время проведения КТ заключается в том, что оно может проникать сквозь ткани и вызывать ионизацию атомов, что может повлечь за собой повреждения в ДНК клеток и возникновение радиационных повреждений. Однако, обычно доза излучения, используемая при проведении КТ, является относительно небольшой и не вызывает существенного вреда для человеческого организма при единичном наблюдении процедуры. Тем не менее, при частом использовании метода КТ или при необходимости повторных исследований, возможно увеличение риска облучения и потенциальных побочных эффектов. Поэтому врач должен тщательно оценить пользу от проведения КТ и риски использования радиационной дозы перед назначением процедуры.</p></div></div><div class="poem-container" data-v-bf4c880b data-v-f19fca7f><div class="review" data-v-f19fca7f><div class="review-title" data-v-f19fca7f><span class="icon" data-v-f19fca7f>question:</span>но все же, даже при небольшом вреде. Что именно происходит с организмом. Можно более подробно?</div><div class="divider" data-v-f19fca7f></div><p class="review-content" data-v-f19fca7f><span class="icon" data-v-f19fca7f>answer:</span>Когда рентгеновское излучение проникает через ткани человеческого тела во время проведения КТ, оно взаимодействует с клетками, вызывая различные биологические эффекты. В частности, выделяют два основных типа воздействия рентгеновского излучения: прямое и косвенное. Прямое воздействие происходит, когда рентгеновские фотоны взаимодействуют непосредственно с молекулами в клетках организма, приводя к ионизации атомов и образованию свободных радикалов. Это может привести к повреждению ДНК и другим биологическим катастрофам, которые могут сопровождаться различными патологическими изменениями. Косвенное воздействие связано с тем, что рентгеновское излучение может взаимодействовать с водными молекулами в клетке, образуя сильные окислительные радикалы, которые также могут привести к повреждению клеток и ДНК. После проведения КТ организм начинает процесс восстановления и ремонта поврежденных клеток. Обычно организм способен справиться с небольшими дозами радиации и восстановить клетки без видимых последствий. Однако при повторных исследованиях или значительных дозах радиации могут возникнуть риски развития радиационных повреждений и побочных эффектов, таких как повышенный риск развития рака и других заболеваний. Поэтому важно соблюдать рекомендации врачей относительно необходимости проведения КТ и минимизировать количество и дозу излучения при выполнении диагностических процедур.</p></div></div><div class="poem-container" data-v-bf4c880b data-v-f19fca7f><div class="review" data-v-f19fca7f><div class="review-title" data-v-f19fca7f><span class="icon" data-v-f19fca7f>question:</span>&quot;образуя сильные окислительные радикалы, которые также могут привести к повреждению клеток и ДНК.&quot; и какие последствия из за этого? Как это влияет на самочувствия?</div><div class="divider" data-v-f19fca7f></div><p class="review-content" data-v-f19fca7f><span class="icon" data-v-f19fca7f>answer:</span>Повреждение клеток и ДНК из-за образования сильных окислительных радикалов в результате воздействия рентгеновского излучения может привести к различным патологическим изменениям и последствиям для организма. В частности, повреждение ДНК может вызвать мутации генов, что в свою очередь может привести к развитию рака или других заболеваний. Кроме того, повреждение клеток и тканей под действием окислительных радикалов может вызвать воспалительные процессы, нарушение работы органов и систем, а также ухудшение общего самочувствия. Это может проявиться в виде усталости, слабости, головной боли, тошноты, изменения аппетита и других симптомов. Следует отметить, что небольшое повреждение клеток и ДНК, вызванное радиацией во время проведения КТ, обычно имеет временный характер и организм способен восстановиться самостоятельно. Однако регулярное облучение или значительные дозы излучения могут увеличить риск возникновения побочных эффектов и нежелательных последствий. Поэтому важно соблюдать меры предосторожности при использовании радиационных методов диагностики, включая минимизацию дозы излучения и четкое обоснование необходимости проведения процедуры. Лечащий врач должен провести оценку рисков и пользы от проведения КТ и принять решение о рациональном использовании данного метода исследования.</p></div></div><!--]--><!----></div><button class="load-more-button" data-v-bf4c880b><span data-v-bf4c880b>See more</span></button></section></div></div></main><!--[--><!--]--><div class="VPFooter" data-v-b0366457><p class="license" data-v-b0366457>Released under the <a class="vt-link link link" href="https://www.m44m.com" target="_blank" rel="noopener noreferrer" data-v-b0366457><!--[-->Ad License<!--]--><!----><!----></a>.</p><p class="copyright" data-v-b0366457>Copyright © 2014-2025 Ad</p></div><!--[--><!--]--></div></div><div class="visually-hidden" aria-live="polite" data-v-e4982c5a> has loaded</div></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_coc.md\":\"B3ITOP5z\",\"about_community-guide.md\":\"Dvcdb1O6\",\"about_faq.md\":\"20McVa9n\",\"about_privacy.md\":\"CcWPOTgs\",\"about_releases.md\":\"GqqAVeGY\",\"about_team.md\":\"Bnw40y2b\",\"chatai_1.md\":\"Bc3HkBVu\",\"chatai_10.md\":\"D0_C590B\",\"chatai_11.md\":\"CZRLGNWB\",\"chatai_12.md\":\"DFmy2MtI\",\"chatai_13.md\":\"BXhSKWIw\",\"chatai_14.md\":\"PfLSNE0X\",\"chatai_15.md\":\"BAJAiTnv\",\"chatai_16.md\":\"D7Hu-mUS\",\"chatai_17.md\":\"BJZlmDFR\",\"chatai_18.md\":\"DuK08XCo\",\"chatai_19.md\":\"Djg52E_T\",\"chatai_2.md\":\"BRDIvg7A\",\"chatai_20.md\":\"CbOnes6r\",\"chatai_21.md\":\"bDshg68L\",\"chatai_22.md\":\"CdGmmzhv\",\"chatai_23.md\":\"DAPBTTmU\",\"chatai_24.md\":\"Cvjx1POJ\",\"chatai_25.md\":\"Bv8fN1bD\",\"chatai_26.md\":\"_-9QkhKt\",\"chatai_27.md\":\"CU7FIQ-n\",\"chatai_28.md\":\"CDpTztFc\",\"chatai_29.md\":\"CP1-NMJ2\",\"chatai_3.md\":\"DrPI5oWU\",\"chatai_30.md\":\"DEKcEjTS\",\"chatai_31.md\":\"BBh1gXct\",\"chatai_32.md\":\"DKQG1nSq\",\"chatai_33.md\":\"DR2yMBTr\",\"chatai_34.md\":\"J0Bql3X5\",\"chatai_35.md\":\"BYKJQBrn\",\"chatai_36.md\":\"C45wDbRH\",\"chatai_37.md\":\"BOkFoH2X\",\"chatai_38.md\":\"B_zjpEya\",\"chatai_39.md\":\"hLcGSzON\",\"chatai_4.md\":\"Ctnu7yZU\",\"chatai_40.md\":\"BNxkrsR8\",\"chatai_41.md\":\"XjUBuNx-\",\"chatai_42.md\":\"D995dgVH\",\"chatai_43.md\":\"DEqStMbC\",\"chatai_44.md\":\"-RXnQIaH\",\"chatai_45.md\":\"_vhGfM94\",\"chatai_46.md\":\"EbphKSpP\",\"chatai_47.md\":\"CR0kj7tT\",\"chatai_48.md\":\"CpJ6pl24\",\"chatai_49.md\":\"CLkgh13J\",\"chatai_5.md\":\"CU82yixU\",\"chatai_50.md\":\"By9vZCsJ\",\"chatai_51.md\":\"BzDbd_B1\",\"chatai_52.md\":\"BPe2d0HG\",\"chatai_53.md\":\"BFKLLNck\",\"chatai_54.md\":\"GIQbSCf1\",\"chatai_55.md\":\"Dj2NmW60\",\"chatai_56.md\":\"CO6TXyK1\",\"chatai_57.md\":\"D3pZPY7R\",\"chatai_58.md\":\"CLjupz-N\",\"chatai_59.md\":\"DOg0HA-T\",\"chatai_6.md\":\"BSjgrB-l\",\"chatai_60.md\":\"BtR-daMu\",\"chatai_61.md\":\"CEbdn6Fr\",\"chatai_62.md\":\"B5DsXjwA\",\"chatai_63.md\":\"Cppblp6i\",\"chatai_64.md\":\"CbeXNlbQ\",\"chatai_65.md\":\"CPXVUjYM\",\"chatai_66.md\":\"BMSnnZoD\",\"chatai_67.md\":\"Cib1zrmF\",\"chatai_68.md\":\"sGCP7x7S\",\"chatai_7.md\":\"BnF-hUyi\",\"chatai_8.md\":\"ChhYJKuO\",\"chatai_9.md\":\"Cv3D0s4A\",\"chatai_index.md\":\"hL1i_FIH\",\"deepseek_1.md\":\"D1RoSOro\",\"deepseek_10.md\":\"DpXK_Pl6\",\"deepseek_11.md\":\"DxHTRM4m\",\"deepseek_12.md\":\"B9BYfHw3\",\"deepseek_13.md\":\"C6tyvcuM\",\"deepseek_14.md\":\"CNc4qF_Y\",\"deepseek_15.md\":\"6UMP4HUL\",\"deepseek_16.md\":\"D6ylaaBI\",\"deepseek_17.md\":\"z2XeYXDM\",\"deepseek_18.md\":\"CELDK3Ze\",\"deepseek_19.md\":\"DyRSxjXO\",\"deepseek_2.md\":\"BOKdH091\",\"deepseek_20.md\":\"BEcvsr7K\",\"deepseek_21.md\":\"DpoYUGYZ\",\"deepseek_22.md\":\"ByBp9HZl\",\"deepseek_23.md\":\"BZIg2zkO\",\"deepseek_24.md\":\"DGhKmBfC\",\"deepseek_25.md\":\"W1uprGDK\",\"deepseek_26.md\":\"C8w5idCw\",\"deepseek_27.md\":\"B0I4nJVd\",\"deepseek_28.md\":\"CLwOC8s1\",\"deepseek_29.md\":\"BNr4zr_I\",\"deepseek_3.md\":\"CmEPTieo\",\"deepseek_30.md\":\"CCNN131z\",\"deepseek_31.md\":\"ccTKuA0f\",\"deepseek_32.md\":\"gxhlmTEG\",\"deepseek_33.md\":\"DbKfI2SU\",\"deepseek_34.md\":\"CM5O03KN\",\"deepseek_35.md\":\"KzRNiKAN\",\"deepseek_36.md\":\"BS1iis_j\",\"deepseek_37.md\":\"Y5VWhaTH\",\"deepseek_38.md\":\"pgL-PwDd\",\"deepseek_39.md\":\"iAhAsAGM\",\"deepseek_4.md\":\"D5BKBSaE\",\"deepseek_40.md\":\"CszDlFu1\",\"deepseek_41.md\":\"BJf4W1Vw\",\"deepseek_42.md\":\"1-M-BLEz\",\"deepseek_43.md\":\"BRqcKVbt\",\"deepseek_44.md\":\"C_6FWCyh\",\"deepseek_45.md\":\"Be_b8Ya6\",\"deepseek_46.md\":\"BCNnkZMX\",\"deepseek_47.md\":\"D8HflLve\",\"deepseek_48.md\":\"DFw_VQ7a\",\"deepseek_49.md\":\"CtxqMnZw\",\"deepseek_5.md\":\"BGNi2Y5C\",\"deepseek_50.md\":\"DHT8YQJl\",\"deepseek_51.md\":\"B0mDlA6Y\",\"deepseek_52.md\":\"C_gsrXB7\",\"deepseek_53.md\":\"Cm2eQ11q\",\"deepseek_54.md\":\"Cy034gVO\",\"deepseek_55.md\":\"CKM5OGEl\",\"deepseek_56.md\":\"f6ANHlAG\",\"deepseek_57.md\":\"B0tL7cu3\",\"deepseek_58.md\":\"BZdhFy_r\",\"deepseek_59.md\":\"ysXftsSK\",\"deepseek_6.md\":\"DsXmpMuK\",\"deepseek_60.md\":\"D6URfPOf\",\"deepseek_61.md\":\"D1EtqpKY\",\"deepseek_62.md\":\"BX5u-OnQ\",\"deepseek_63.md\":\"CpNx3wFk\",\"deepseek_64.md\":\"xg7bd-Oq\",\"deepseek_65.md\":\"BsAdif35\",\"deepseek_66.md\":\"DukSga2w\",\"deepseek_67.md\":\"CDCtEjXd\",\"deepseek_68.md\":\"C87GbP_M\",\"deepseek_7.md\":\"BRO4XIr_\",\"deepseek_8.md\":\"GkTvgxC8\",\"deepseek_9.md\":\"CyTgnZXs\",\"drive_1.md\":\"Dqjf432X\",\"drive_10.md\":\"BxCHIfTC\",\"drive_11.md\":\"MqdHGmer\",\"drive_12.md\":\"DV9Nujn9\",\"drive_13.md\":\"BiYEzKFY\",\"drive_14.md\":\"BmabkeFT\",\"drive_15.md\":\"DEF8TXO-\",\"drive_16.md\":\"Dk_6StI_\",\"drive_17.md\":\"ByEjg3mp\",\"drive_18.md\":\"BDeMPeYV\",\"drive_19.md\":\"Cirg9Kag\",\"drive_2.md\":\"BVXHmPhB\",\"drive_20.md\":\"bzM7H4pt\",\"drive_21.md\":\"BmBgZ-1Q\",\"drive_22.md\":\"SbG38Nq_\",\"drive_23.md\":\"HePFndml\",\"drive_24.md\":\"Cj_s8bhV\",\"drive_25.md\":\"BXwfi7xP\",\"drive_26.md\":\"DmY4aBD3\",\"drive_27.md\":\"DeL-7FVX\",\"drive_28.md\":\"CHHzPenK\",\"drive_29.md\":\"Drj22C6-\",\"drive_3.md\":\"D1dasaLc\",\"drive_30.md\":\"BiIhBHa8\",\"drive_31.md\":\"CkZRj73p\",\"drive_32.md\":\"B6ldVbdU\",\"drive_33.md\":\"D1GqWZAi\",\"drive_34.md\":\"BEwT6iLC\",\"drive_35.md\":\"Dxy-d21i\",\"drive_36.md\":\"DNyQYiEo\",\"drive_37.md\":\"C1gHN6F_\",\"drive_38.md\":\"CIp_tb5l\",\"drive_39.md\":\"BwLEtF-W\",\"drive_4.md\":\"Bg4zJCpm\",\"drive_40.md\":\"Ca4nYQSi\",\"drive_41.md\":\"rZY1DQFZ\",\"drive_42.md\":\"CwxT2Dyw\",\"drive_43.md\":\"BAbYjj57\",\"drive_44.md\":\"Buj_LhpE\",\"drive_45.md\":\"DhwNdtsS\",\"drive_46.md\":\"Bk4-I-6k\",\"drive_47.md\":\"C5Bd2EOK\",\"drive_48.md\":\"D53aeirr\",\"drive_49.md\":\"CDC1nvek\",\"drive_5.md\":\"C9cwXULZ\",\"drive_50.md\":\"B71Vahrf\",\"drive_51.md\":\"C3sr1A7N\",\"drive_52.md\":\"DzO2dMh3\",\"drive_53.md\":\"CoLIye8e\",\"drive_54.md\":\"YLJB6ckY\",\"drive_55.md\":\"CMxtjet3\",\"drive_56.md\":\"DOoC6P_O\",\"drive_57.md\":\"CTbLQFlO\",\"drive_58.md\":\"DHXGBLV4\",\"drive_59.md\":\"UEnEXdZQ\",\"drive_6.md\":\"B5wrwFAd\",\"drive_60.md\":\"BedVHbqz\",\"drive_7.md\":\"4FCfAnyz\",\"drive_8.md\":\"WJGV82uy\",\"drive_9.md\":\"BVcIivOw\",\"drive_aiprompt.md\":\"BB41XtLC\",\"drive_donation.md\":\"8wvNJAVf\",\"drive_prompt.md\":\"BoXlmEzc\",\"drive_promptlibrary.md\":\"D2zvzxSB\",\"drive_team.md\":\"CkNmWMDG\",\"ecosystem_chatgpt.md\":\"CecoSlph\",\"ecosystem_deepseek.md\":\"CF1UvxTr\",\"ecosystem_navigation.md\":\"wKlND_1J\",\"ecosystem_newsletters.md\":\"DaQl6Mbh\",\"ecosystem_promptes.md\":\"DZRC8AXP\",\"ecosystem_themes.md\":\"DcxYtm4j\",\"error-reference_index.md\":\"C8cWCSv1\",\"examples_index.md\":\"DYIYBDwT\",\"grok_1.md\":\"BYJAMSSz\",\"grok_10.md\":\"CEV7U4XG\",\"grok_11.md\":\"DzMgTpNX\",\"grok_12.md\":\"B79I3mOC\",\"grok_13.md\":\"_vOiXj92\",\"grok_14.md\":\"CBgWpLk5\",\"grok_15.md\":\"Cmb8wucI\",\"grok_16.md\":\"BsiILdta\",\"grok_17.md\":\"hB-xpD5K\",\"grok_18.md\":\"DnfTrckO\",\"grok_19.md\":\"DVhVBlsI\",\"grok_2.md\":\"DnQspXu-\",\"grok_20.md\":\"C2kuJIXq\",\"grok_21.md\":\"BAHoWMVq\",\"grok_22.md\":\"CaFMUoTC\",\"grok_23.md\":\"DrswpU1D\",\"grok_24.md\":\"DG8QZVTP\",\"grok_25.md\":\"DPsJOf_k\",\"grok_26.md\":\"P08hV6d6\",\"grok_27.md\":\"D5Lk3R1Q\",\"grok_28.md\":\"BIu4I0XE\",\"grok_29.md\":\"Dc0dwYqV\",\"grok_3.md\":\"CZRhLVYz\",\"grok_30.md\":\"VYqM0DuO\",\"grok_31.md\":\"2j5DQeAF\",\"grok_32.md\":\"CRTNZRzD\",\"grok_33.md\":\"T_l754x2\",\"grok_34.md\":\"CZoidkNi\",\"grok_35.md\":\"Cr3VWgDC\",\"grok_36.md\":\"B1YktYDi\",\"grok_37.md\":\"D7qP1M0w\",\"grok_38.md\":\"CQ_No7TA\",\"grok_39.md\":\"BGJ8IgXo\",\"grok_4.md\":\"uq1HhaFB\",\"grok_40.md\":\"9clhVFPM\",\"grok_41.md\":\"Dh1qpFwS\",\"grok_42.md\":\"B8vjDsW3\",\"grok_43.md\":\"CAvBgWpK\",\"grok_44.md\":\"DHi94Ccu\",\"grok_45.md\":\"B01OPDjJ\",\"grok_46.md\":\"D3m8yBHF\",\"grok_47.md\":\"aHi_RLdy\",\"grok_48.md\":\"9f2qr8FW\",\"grok_49.md\":\"DlrtfdA6\",\"grok_5.md\":\"B14PhHAw\",\"grok_50.md\":\"D-kd9csM\",\"grok_51.md\":\"C7aKrGOI\",\"grok_52.md\":\"D-07ZmKA\",\"grok_53.md\":\"4MVxYni6\",\"grok_54.md\":\"C9yjdxWC\",\"grok_55.md\":\"CVOCX3-U\",\"grok_56.md\":\"CRnSVj6y\",\"grok_57.md\":\"BwHXNUwg\",\"grok_58.md\":\"CMsfpzuk\",\"grok_59.md\":\"DXhd9hV0\",\"grok_6.md\":\"C55qkj92\",\"grok_60.md\":\"COGNRikg\",\"grok_61.md\":\"C3BldWYE\",\"grok_62.md\":\"Dcf7Gizc\",\"grok_63.md\":\"BiyWb266\",\"grok_64.md\":\"gslQ4baA\",\"grok_65.md\":\"CER7hY1k\",\"grok_66.md\":\"at6QsV9p\",\"grok_67.md\":\"BeElscWV\",\"grok_68.md\":\"B4xcuF-r\",\"grok_7.md\":\"DS9VSVXo\",\"grok_8.md\":\"CfEhJ8iy\",\"grok_9.md\":\"PyPLLLTO\",\"guide_1.md\":\"CVkBTQ1Q\",\"guide_10.md\":\"BnSYB-RS\",\"guide_11.md\":\"CqYJQesi\",\"guide_12.md\":\"e-STsfyN\",\"guide_13.md\":\"dxbHfzO_\",\"guide_14.md\":\"BzYo0zkT\",\"guide_15.md\":\"-v37ORKG\",\"guide_16.md\":\"BdVkwQse\",\"guide_17.md\":\"Dp1XDf9s\",\"guide_18.md\":\"Y0K_CJ09\",\"guide_19.md\":\"DliHpm17\",\"guide_2.md\":\"BlAA7VRt\",\"guide_20.md\":\"B0xhbR4q\",\"guide_21.md\":\"Cqb51b9J\",\"guide_22.md\":\"Db4XGkDS\",\"guide_23.md\":\"2FyEXjqP\",\"guide_24.md\":\"De36Boof\",\"guide_25.md\":\"wbIvOMn8\",\"guide_26.md\":\"CPBM-kKx\",\"guide_27.md\":\"Cp0DXL_G\",\"guide_28.md\":\"D8IdCsuJ\",\"guide_29.md\":\"BjcJfcxl\",\"guide_3.md\":\"DoV2hjyX\",\"guide_30.md\":\"Bdxoq3pg\",\"guide_31.md\":\"BGONykC1\",\"guide_32.md\":\"Cx-u0Hcq\",\"guide_33.md\":\"Bawaa2uW\",\"guide_34.md\":\"BNR_9sH1\",\"guide_35.md\":\"CYzweeOX\",\"guide_36.md\":\"CpcaDkNt\",\"guide_37.md\":\"g018DdZZ\",\"guide_38.md\":\"Bggq2Y7l\",\"guide_39.md\":\"Cmi7tydY\",\"guide_4.md\":\"gUz6uUrF\",\"guide_40.md\":\"D5jeIx_u\",\"guide_41.md\":\"Cta8c61r\",\"guide_42.md\":\"CZPoS_tN\",\"guide_43.md\":\"MnxF249_\",\"guide_44.md\":\"Bg6wUqrj\",\"guide_45.md\":\"D4mFrfDj\",\"guide_46.md\":\"3fV-GtWW\",\"guide_47.md\":\"CobHDVlB\",\"guide_48.md\":\"DaAJ7QsK\",\"guide_49.md\":\"DwZA9YoP\",\"guide_5.md\":\"DOR_eMtD\",\"guide_50.md\":\"BA4Xi7ng\",\"guide_51.md\":\"AuFC-_bO\",\"guide_52.md\":\"Rwigev6j\",\"guide_53.md\":\"DsANESdK\",\"guide_54.md\":\"DDf8Q14f\",\"guide_55.md\":\"DGy4pAyl\",\"guide_56.md\":\"C2ex-tSz\",\"guide_57.md\":\"BTpmSaIw\",\"guide_58.md\":\"CCMOHaHV\",\"guide_59.md\":\"xDmmEopI\",\"guide_6.md\":\"DJA0C8wR\",\"guide_60.md\":\"CLcNuwQT\",\"guide_61.md\":\"COZUF5_E\",\"guide_62.md\":\"DTq0ECRP\",\"guide_63.md\":\"DvVT4Ol7\",\"guide_64.md\":\"DUnkW6Af\",\"guide_65.md\":\"gCuHwRrZ\",\"guide_66.md\":\"BeHpecAH\",\"guide_67.md\":\"Caq2GaB_\",\"guide_68.md\":\"efQWqG5m\",\"guide_7.md\":\"DxhqqeHB\",\"guide_8.md\":\"GVngySvd\",\"guide_9.md\":\"ComHJWcx\",\"index.md\":\"DTnXgCjz\",\"library_1.md\":\"CNAMMWYo\",\"library_10.md\":\"BFwf4bVA\",\"library_11.md\":\"q_b_0Qkm\",\"library_12.md\":\"8k9oVBqz\",\"library_13.md\":\"BSLYGZD_\",\"library_14.md\":\"CV1vos9s\",\"library_15.md\":\"DysAh3qB\",\"library_16.md\":\"yMaGGiih\",\"library_17.md\":\"dbTtW_Ma\",\"library_18.md\":\"D6-fFMvw\",\"library_19.md\":\"BLAo4SNB\",\"library_2.md\":\"YfiRDlfU\",\"library_20.md\":\"CJLz-P-u\",\"library_21.md\":\"CRSPtK6E\",\"library_22.md\":\"JjP-Nnzg\",\"library_23.md\":\"B8dmieJ0\",\"library_24.md\":\"COmrpg3b\",\"library_25.md\":\"DUoHk1Tu\",\"library_26.md\":\"BF7_slzw\",\"library_27.md\":\"CIZ5Rpf9\",\"library_28.md\":\"DUNIiMKZ\",\"library_29.md\":\"CVxG7iXL\",\"library_3.md\":\"CieJQvUq\",\"library_30.md\":\"cEK8x9Lz\",\"library_31.md\":\"C-zow9xo\",\"library_32.md\":\"BS3nABr9\",\"library_33.md\":\"BEwQGvrK\",\"library_34.md\":\"eQT_VqMl\",\"library_35.md\":\"DQL5CTnK\",\"library_36.md\":\"Dui5Fo1-\",\"library_37.md\":\"C5nOE6Je\",\"library_38.md\":\"EYOXwjuP\",\"library_39.md\":\"WX6npEuY\",\"library_4.md\":\"BoviwLLo\",\"library_40.md\":\"CRR2HgaP\",\"library_41.md\":\"CucQbH7R\",\"library_42.md\":\"DUJCEEJJ\",\"library_43.md\":\"BiKAjjLh\",\"library_44.md\":\"CSzeWuZX\",\"library_45.md\":\"C_GshNDi\",\"library_46.md\":\"T16fP7Zm\",\"library_47.md\":\"BeFS6IAX\",\"library_48.md\":\"Bp9whQko\",\"library_49.md\":\"DbdZxIkn\",\"library_5.md\":\"C-pQZTlm\",\"library_50.md\":\"BViADYoG\",\"library_51.md\":\"a1I6Easl\",\"library_52.md\":\"DpgWeVZz\",\"library_53.md\":\"CBijkvc7\",\"library_54.md\":\"Bh7NtfJa\",\"library_55.md\":\"BGygK88-\",\"library_56.md\":\"CGUA6SOe\",\"library_57.md\":\"CPDEicH_\",\"library_58.md\":\"CGGc9FNF\",\"library_59.md\":\"Ba7YllZ7\",\"library_6.md\":\"BgTJ21m8\",\"library_60.md\":\"D8DMoKVZ\",\"library_61.md\":\"DP3d-dqX\",\"library_62.md\":\"DJy2vGb7\",\"library_63.md\":\"D6ptBCDU\",\"library_64.md\":\"DttdFm2q\",\"library_65.md\":\"suaFMSZM\",\"library_66.md\":\"CN0X6C7I\",\"library_67.md\":\"DqCgHlXr\",\"library_68.md\":\"BjsVSHJl\",\"library_7.md\":\"BOxD7yFK\",\"library_8.md\":\"DhUk6Gxp\",\"library_9.md\":\"CG2Jusq1\",\"partners_all.md\":\"DrI_oKr-\",\"partners_curotec.md\":\"C5GS61rR\",\"partners_herodevs.md\":\"BVDxGK-m\",\"partners_index.md\":\"BBcUVcAI\",\"partners_monterail.md\":\"B627I69r\",\"partners_passionatepeople.md\":\"BDAHuxir\",\"partners_redberry.md\":\"B-Sf3MRF\",\"partners_vehikl.md\":\"CjJYaD5l\",\"partners_webreinvent.md\":\"CuHjowhF\",\"quotes_1.md\":\"DEj_14d9\",\"quotes_10.md\":\"Cc1DI8sS\",\"quotes_11.md\":\"BZtqqXI8\",\"quotes_12.md\":\"CJG4Dx7t\",\"quotes_13.md\":\"CAfX1ot-\",\"quotes_14.md\":\"D8alBDaU\",\"quotes_15.md\":\"Dpif73Lx\",\"quotes_16.md\":\"CKedNEEa\",\"quotes_17.md\":\"BPiicLaK\",\"quotes_18.md\":\"MFRvb6OQ\",\"quotes_19.md\":\"2PP5EJXb\",\"quotes_2.md\":\"Cv4k02Ny\",\"quotes_20.md\":\"YHv1L8kP\",\"quotes_21.md\":\"CfsLE-vu\",\"quotes_22.md\":\"ChX0Errx\",\"quotes_23.md\":\"qu6VYClM\",\"quotes_24.md\":\"DefR72GC\",\"quotes_25.md\":\"C4wnbTwo\",\"quotes_26.md\":\"Cbgo5a5b\",\"quotes_27.md\":\"CuvTYvTM\",\"quotes_28.md\":\"xtnFKi09\",\"quotes_29.md\":\"B8aN9B1w\",\"quotes_3.md\":\"Dy0omiOT\",\"quotes_30.md\":\"Dqr-oGyF\",\"quotes_31.md\":\"DPQYZbZ7\",\"quotes_32.md\":\"DTPnbH8b\",\"quotes_33.md\":\"CP6B6xp6\",\"quotes_34.md\":\"BPY4iC-S\",\"quotes_35.md\":\"BoXBj2l9\",\"quotes_36.md\":\"M0BtaefY\",\"quotes_37.md\":\"C8roI1fj\",\"quotes_38.md\":\"Cq15w75C\",\"quotes_39.md\":\"brnVw6-4\",\"quotes_4.md\":\"VFlF7fQG\",\"quotes_40.md\":\"CYf3wEpy\",\"quotes_41.md\":\"D_69l_By\",\"quotes_42.md\":\"COo4SqLj\",\"quotes_43.md\":\"CoAglPB6\",\"quotes_44.md\":\"Dyf0EKN8\",\"quotes_45.md\":\"BiIWylq5\",\"quotes_46.md\":\"D7linZwY\",\"quotes_47.md\":\"CKd39ypP\",\"quotes_48.md\":\"CKvXxayB\",\"quotes_49.md\":\"DQ0_Fbnr\",\"quotes_5.md\":\"XUoME6ET\",\"quotes_50.md\":\"DEVVb6RZ\",\"quotes_51.md\":\"R_HVJlKP\",\"quotes_52.md\":\"C71qjFqo\",\"quotes_53.md\":\"D82ZW4az\",\"quotes_54.md\":\"B4VPh9dQ\",\"quotes_55.md\":\"Bvp9nN_x\",\"quotes_56.md\":\"DbwMhXsp\",\"quotes_57.md\":\"CNffygIL\",\"quotes_58.md\":\"CsslaSY2\",\"quotes_59.md\":\"C33L0QKa\",\"quotes_6.md\":\"B_S1Y1o4\",\"quotes_60.md\":\"DlVrnzQF\",\"quotes_61.md\":\"FW4cbqtv\",\"quotes_62.md\":\"INXAnBtH\",\"quotes_63.md\":\"CiOGVa85\",\"quotes_64.md\":\"9K36RVRp\",\"quotes_65.md\":\"DvogRhjn\",\"quotes_66.md\":\"CMsdzVhu\",\"quotes_67.md\":\"D4NVM-uo\",\"quotes_68.md\":\"B-oxLy3Q\",\"quotes_7.md\":\"lr8syXSJ\",\"quotes_8.md\":\"DxyS6YdN\",\"quotes_9.md\":\"DKZEnIJ8\",\"swap_app.md\":\"dX62wfc0\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh\",\"dir\":\"ltr\",\"title\":\"Ad\",\"description\":\"Ad\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/images/logo.svg\",\"nav\":[{\"text\":\"data\",\"activeMatch\":\"^/drive/\",\"items\":[{\"text\":\"data1\",\"link\":\"/drive/1\"},{\"text\":\"data2\",\"link\":\"/drive/2\"},{\"text\":\"data3\",\"link\":\"/drive/3\"},{\"text\":\"data4\",\"link\":\"/drive/4\"},{\"text\":\"data5\",\"link\":\"/drive/5\"},{\"text\":\"data6\",\"link\":\"/drive/6\"},{\"text\":\"data7\",\"link\":\"/drive/7\"},{\"text\":\"data8\",\"link\":\"/drive/8\"},{\"text\":\"data9\",\"link\":\"/drive/9\"},{\"text\":\"data10\",\"link\":\"/drive/10\"},{\"text\":\"data11\",\"link\":\"/drive/11\"},{\"text\":\"data12\",\"link\":\"/drive/12\"},{\"text\":\"data13\",\"link\":\"/drive/13\"},{\"text\":\"data14\",\"link\":\"/drive/14\"},{\"text\":\"data15\",\"link\":\"/drive/15\"},{\"text\":\"data16\",\"link\":\"/drive/16\"},{\"text\":\"data17\",\"link\":\"/drive/17\"},{\"text\":\"data18\",\"link\":\"/drive/18\"},{\"text\":\"data19\",\"link\":\"/drive/19\"},{\"text\":\"data20\",\"link\":\"/drive/20\"},{\"text\":\"data21\",\"link\":\"/drive/21\"},{\"text\":\"data22\",\"link\":\"/drive/22\"},{\"text\":\"data23\",\"link\":\"/drive/23\"},{\"text\":\"data24\",\"link\":\"/drive/24\"},{\"text\":\"data25\",\"link\":\"/drive/25\"},{\"text\":\"data26\",\"link\":\"/drive/26\"},{\"text\":\"data27\",\"link\":\"/drive/27\"},{\"text\":\"data28\",\"link\":\"/drive/28\"},{\"text\":\"data29\",\"link\":\"/drive/29\"},{\"text\":\"data30\",\"link\":\"/drive/30\"},{\"text\":\"data31\",\"link\":\"/drive/31\"},{\"text\":\"data32\",\"link\":\"/drive/32\"},{\"text\":\"data33\",\"link\":\"/drive/33\"},{\"text\":\"data34\",\"link\":\"/drive/34\"},{\"text\":\"data35\",\"link\":\"/drive/35\"},{\"text\":\"data36\",\"link\":\"/drive/36\"},{\"text\":\"data37\",\"link\":\"/drive/37\"},{\"text\":\"data38\",\"link\":\"/drive/38\"},{\"text\":\"data39\",\"link\":\"/drive/39\"},{\"text\":\"data40\",\"link\":\"/drive/40\"},{\"text\":\"data41\",\"link\":\"/drive/41\"},{\"text\":\"data42\",\"link\":\"/drive/42\"},{\"text\":\"data43\",\"link\":\"/drive/43\"},{\"text\":\"data44\",\"link\":\"/drive/44\"},{\"text\":\"data45\",\"link\":\"/drive/45\"},{\"text\":\"data46\",\"link\":\"/drive/46\"},{\"text\":\"data47\",\"link\":\"/drive/47\"},{\"text\":\"data48\",\"link\":\"/drive/48\"},{\"text\":\"data49\",\"link\":\"/drive/49\"},{\"text\":\"data50\",\"link\":\"/drive/50\"},{\"text\":\"data51\",\"link\":\"/drive/51\"},{\"text\":\"data52\",\"link\":\"/drive/52\"},{\"text\":\"data53\",\"link\":\"/drive/53\"},{\"text\":\"data54\",\"link\":\"/drive/54\"},{\"text\":\"data55\",\"link\":\"/drive/55\"},{\"text\":\"data56\",\"link\":\"/drive/56\"},{\"text\":\"data57\",\"link\":\"/drive/57\"},{\"text\":\"data58\",\"link\":\"/drive/58\"},{\"text\":\"data59\",\"link\":\"/drive/59\"},{\"text\":\"data60\",\"link\":\"/drive/60\"}]},{\"text\":\"grok\",\"activeMatch\":\"^/grok/\",\"items\":[{\"text\":\"grok1\",\"link\":\"/grok/1\"},{\"text\":\"grok2\",\"link\":\"/grok/2\"},{\"text\":\"grok3\",\"link\":\"/grok/3\"},{\"text\":\"grok4\",\"link\":\"/grok/4\"},{\"text\":\"grok5\",\"link\":\"/grok/5\"},{\"text\":\"grok6\",\"link\":\"/grok/6\"},{\"text\":\"grok7\",\"link\":\"/grok/7\"},{\"text\":\"grok8\",\"link\":\"/grok/8\"},{\"text\":\"grok9\",\"link\":\"/grok/9\"},{\"text\":\"grok10\",\"link\":\"/grok/10\"},{\"text\":\"grok11\",\"link\":\"/grok/11\"},{\"text\":\"grok12\",\"link\":\"/grok/12\"},{\"text\":\"grok13\",\"link\":\"/grok/13\"},{\"text\":\"grok14\",\"link\":\"/grok/14\"},{\"text\":\"grok15\",\"link\":\"/grok/15\"},{\"text\":\"grok16\",\"link\":\"/grok/16\"},{\"text\":\"grok17\",\"link\":\"/grok/17\"},{\"text\":\"grok18\",\"link\":\"/grok/18\"},{\"text\":\"grok19\",\"link\":\"/grok/19\"},{\"text\":\"grok20\",\"link\":\"/grok/20\"},{\"text\":\"grok21\",\"link\":\"/grok/21\"},{\"text\":\"grok22\",\"link\":\"/grok/22\"},{\"text\":\"grok23\",\"link\":\"/grok/23\"},{\"text\":\"grok24\",\"link\":\"/grok/24\"},{\"text\":\"grok25\",\"link\":\"/grok/25\"},{\"text\":\"grok26\",\"link\":\"/grok/26\"},{\"text\":\"grok27\",\"link\":\"/grok/27\"},{\"text\":\"grok28\",\"link\":\"/grok/28\"},{\"text\":\"grok29\",\"link\":\"/grok/29\"},{\"text\":\"grok30\",\"link\":\"/grok/30\"},{\"text\":\"grok31\",\"link\":\"/grok/31\"},{\"text\":\"grok32\",\"link\":\"/grok/32\"},{\"text\":\"grok33\",\"link\":\"/grok/33\"},{\"text\":\"grok34\",\"link\":\"/grok/34\"},{\"text\":\"grok35\",\"link\":\"/grok/35\"},{\"text\":\"grok36\",\"link\":\"/grok/36\"},{\"text\":\"grok37\",\"link\":\"/grok/37\"},{\"text\":\"grok38\",\"link\":\"/grok/38\"},{\"text\":\"grok39\",\"link\":\"/grok/39\"},{\"text\":\"grok40\",\"link\":\"/grok/40\"},{\"text\":\"grok41\",\"link\":\"/grok/41\"},{\"text\":\"grok42\",\"link\":\"/grok/42\"},{\"text\":\"grok43\",\"link\":\"/grok/43\"},{\"text\":\"grok44\",\"link\":\"/grok/44\"},{\"text\":\"grok45\",\"link\":\"/grok/45\"},{\"text\":\"grok46\",\"link\":\"/grok/46\"},{\"text\":\"grok47\",\"link\":\"/grok/47\"},{\"text\":\"grok48\",\"link\":\"/grok/48\"},{\"text\":\"grok49\",\"link\":\"/grok/49\"},{\"text\":\"grok50\",\"link\":\"/grok/50\"},{\"text\":\"grok51\",\"link\":\"/grok/51\"},{\"text\":\"grok52\",\"link\":\"/grok/52\"},{\"text\":\"grok53\",\"link\":\"/grok/53\"},{\"text\":\"grok54\",\"link\":\"/grok/54\"},{\"text\":\"grok55\",\"link\":\"/grok/55\"},{\"text\":\"grok56\",\"link\":\"/grok/56\"},{\"text\":\"grok57\",\"link\":\"/grok/57\"},{\"text\":\"grok58\",\"link\":\"/grok/58\"},{\"text\":\"grok59\",\"link\":\"/grok/59\"},{\"text\":\"grok60\",\"link\":\"/grok/60\"},{\"text\":\"grok61\",\"link\":\"/grok/61\"},{\"text\":\"grok62\",\"link\":\"/grok/62\"},{\"text\":\"grok63\",\"link\":\"/grok/63\"},{\"text\":\"grok64\",\"link\":\"/grok/64\"},{\"text\":\"grok65\",\"link\":\"/grok/65\"},{\"text\":\"grok66\",\"link\":\"/grok/66\"},{\"text\":\"grok67\",\"link\":\"/grok/67\"},{\"text\":\"grok68\",\"link\":\"/grok/68\"}]},{\"text\":\"wiki\",\"activeMatch\":\"^/guide/\",\"items\":[{\"text\":\"wiki1\",\"link\":\"/guide/1\"},{\"text\":\"wiki2\",\"link\":\"/guide/2\"},{\"text\":\"wiki3\",\"link\":\"/guide/3\"},{\"text\":\"wiki4\",\"link\":\"/guide/4\"},{\"text\":\"wiki5\",\"link\":\"/guide/5\"},{\"text\":\"wiki6\",\"link\":\"/guide/6\"},{\"text\":\"wiki7\",\"link\":\"/guide/7\"},{\"text\":\"wiki8\",\"link\":\"/guide/8\"},{\"text\":\"wiki9\",\"link\":\"/guide/9\"},{\"text\":\"wiki10\",\"link\":\"/guide/10\"},{\"text\":\"wiki11\",\"link\":\"/guide/11\"},{\"text\":\"wiki12\",\"link\":\"/guide/12\"},{\"text\":\"wiki13\",\"link\":\"/guide/13\"},{\"text\":\"wiki14\",\"link\":\"/guide/14\"},{\"text\":\"wiki15\",\"link\":\"/guide/15\"},{\"text\":\"wiki16\",\"link\":\"/guide/16\"},{\"text\":\"wiki17\",\"link\":\"/guide/17\"},{\"text\":\"wiki18\",\"link\":\"/guide/18\"},{\"text\":\"wiki19\",\"link\":\"/guide/19\"},{\"text\":\"wiki20\",\"link\":\"/guide/20\"},{\"text\":\"wiki21\",\"link\":\"/guide/21\"},{\"text\":\"wiki22\",\"link\":\"/guide/22\"},{\"text\":\"wiki23\",\"link\":\"/guide/23\"},{\"text\":\"wiki24\",\"link\":\"/guide/24\"},{\"text\":\"wiki25\",\"link\":\"/guide/25\"},{\"text\":\"wiki26\",\"link\":\"/guide/26\"},{\"text\":\"wiki27\",\"link\":\"/guide/27\"},{\"text\":\"wiki28\",\"link\":\"/guide/28\"},{\"text\":\"wiki29\",\"link\":\"/guide/29\"},{\"text\":\"wiki30\",\"link\":\"/guide/30\"},{\"text\":\"wiki31\",\"link\":\"/guide/31\"},{\"text\":\"wiki32\",\"link\":\"/guide/32\"},{\"text\":\"wiki33\",\"link\":\"/guide/33\"},{\"text\":\"wiki34\",\"link\":\"/guide/34\"},{\"text\":\"wiki35\",\"link\":\"/guide/35\"},{\"text\":\"wiki36\",\"link\":\"/guide/36\"},{\"text\":\"wiki37\",\"link\":\"/guide/37\"},{\"text\":\"wiki38\",\"link\":\"/guide/38\"},{\"text\":\"wiki39\",\"link\":\"/guide/39\"},{\"text\":\"wiki40\",\"link\":\"/guide/40\"},{\"text\":\"wiki41\",\"link\":\"/guide/41\"},{\"text\":\"wiki42\",\"link\":\"/guide/42\"},{\"text\":\"wiki43\",\"link\":\"/guide/43\"},{\"text\":\"wiki44\",\"link\":\"/guide/44\"},{\"text\":\"wiki45\",\"link\":\"/guide/45\"},{\"text\":\"wiki46\",\"link\":\"/guide/46\"},{\"text\":\"wiki47\",\"link\":\"/guide/47\"},{\"text\":\"wiki48\",\"link\":\"/guide/48\"},{\"text\":\"wiki49\",\"link\":\"/guide/49\"},{\"text\":\"wiki50\",\"link\":\"/guide/50\"},{\"text\":\"wiki51\",\"link\":\"/guide/51\"},{\"text\":\"wiki52\",\"link\":\"/guide/52\"},{\"text\":\"wiki53\",\"link\":\"/guide/53\"},{\"text\":\"wiki54\",\"link\":\"/guide/54\"},{\"text\":\"wiki55\",\"link\":\"/guide/55\"},{\"text\":\"wiki56\",\"link\":\"/guide/56\"},{\"text\":\"wiki57\",\"link\":\"/guide/57\"},{\"text\":\"wiki58\",\"link\":\"/guide/58\"},{\"text\":\"wiki59\",\"link\":\"/guide/59\"},{\"text\":\"wiki60\",\"link\":\"/guide/60\"},{\"text\":\"wiki61\",\"link\":\"/guide/61\"},{\"text\":\"wiki62\",\"link\":\"/guide/62\"},{\"text\":\"wiki63\",\"link\":\"/guide/63\"},{\"text\":\"wiki64\",\"link\":\"/guide/64\"},{\"text\":\"wiki65\",\"link\":\"/guide/65\"},{\"text\":\"wiki66\",\"link\":\"/guide/66\"},{\"text\":\"wiki67\",\"link\":\"/guide/67\"},{\"text\":\"wiki68\",\"link\":\"/guide/68\"}]},{\"text\":\"deep\",\"activeMatch\":\"^/deepseek/\",\"items\":[{\"text\":\"deep1\",\"link\":\"/deepseek/1\"},{\"text\":\"deep2\",\"link\":\"/deepseek/2\"},{\"text\":\"deep3\",\"link\":\"/deepseek/3\"},{\"text\":\"deep4\",\"link\":\"/deepseek/4\"},{\"text\":\"deep5\",\"link\":\"/deepseek/5\"},{\"text\":\"deep6\",\"link\":\"/deepseek/6\"},{\"text\":\"deep7\",\"link\":\"/deepseek/7\"},{\"text\":\"deep8\",\"link\":\"/deepseek/8\"},{\"text\":\"deep9\",\"link\":\"/deepseek/9\"},{\"text\":\"deep10\",\"link\":\"/deepseek/10\"},{\"text\":\"deep11\",\"link\":\"/deepseek/11\"},{\"text\":\"deep12\",\"link\":\"/deepseek/12\"},{\"text\":\"deep13\",\"link\":\"/deepseek/13\"},{\"text\":\"deep14\",\"link\":\"/deepseek/14\"},{\"text\":\"deep15\",\"link\":\"/deepseek/15\"},{\"text\":\"deep16\",\"link\":\"/deepseek/16\"},{\"text\":\"deep17\",\"link\":\"/deepseek/17\"},{\"text\":\"deep18\",\"link\":\"/deepseek/18\"},{\"text\":\"deep19\",\"link\":\"/deepseek/19\"},{\"text\":\"deep20\",\"link\":\"/deepseek/20\"},{\"text\":\"deep21\",\"link\":\"/deepseek/21\"},{\"text\":\"deep22\",\"link\":\"/deepseek/22\"},{\"text\":\"deep23\",\"link\":\"/deepseek/23\"},{\"text\":\"deep24\",\"link\":\"/deepseek/24\"},{\"text\":\"deep25\",\"link\":\"/deepseek/25\"},{\"text\":\"deep26\",\"link\":\"/deepseek/26\"},{\"text\":\"deep27\",\"link\":\"/deepseek/27\"},{\"text\":\"deep28\",\"link\":\"/deepseek/28\"},{\"text\":\"deep29\",\"link\":\"/deepseek/29\"},{\"text\":\"deep30\",\"link\":\"/deepseek/30\"},{\"text\":\"deep31\",\"link\":\"/deepseek/31\"},{\"text\":\"deep32\",\"link\":\"/deepseek/32\"},{\"text\":\"deep33\",\"link\":\"/deepseek/33\"},{\"text\":\"deep34\",\"link\":\"/deepseek/34\"},{\"text\":\"deep35\",\"link\":\"/deepseek/35\"},{\"text\":\"deep36\",\"link\":\"/deepseek/36\"},{\"text\":\"deep37\",\"link\":\"/deepseek/37\"},{\"text\":\"deep38\",\"link\":\"/deepseek/38\"},{\"text\":\"deep39\",\"link\":\"/deepseek/39\"},{\"text\":\"deep40\",\"link\":\"/deepseek/40\"},{\"text\":\"deep41\",\"link\":\"/deepseek/41\"},{\"text\":\"deep42\",\"link\":\"/deepseek/42\"},{\"text\":\"deep43\",\"link\":\"/deepseek/43\"},{\"text\":\"deep44\",\"link\":\"/deepseek/44\"},{\"text\":\"deep45\",\"link\":\"/deepseek/45\"},{\"text\":\"deep46\",\"link\":\"/deepseek/46\"},{\"text\":\"deep47\",\"link\":\"/deepseek/47\"},{\"text\":\"deep48\",\"link\":\"/deepseek/48\"},{\"text\":\"deep49\",\"link\":\"/deepseek/49\"},{\"text\":\"deep50\",\"link\":\"/deepseek/50\"},{\"text\":\"deep51\",\"link\":\"/deepseek/51\"},{\"text\":\"deep52\",\"link\":\"/deepseek/52\"},{\"text\":\"deep53\",\"link\":\"/deepseek/53\"},{\"text\":\"deep54\",\"link\":\"/deepseek/54\"},{\"text\":\"deep55\",\"link\":\"/deepseek/55\"},{\"text\":\"deep56\",\"link\":\"/deepseek/56\"},{\"text\":\"deep57\",\"link\":\"/deepseek/57\"},{\"text\":\"deep58\",\"link\":\"/deepseek/58\"},{\"text\":\"deep59\",\"link\":\"/deepseek/59\"},{\"text\":\"deep60\",\"link\":\"/deepseek/60\"},{\"text\":\"deep61\",\"link\":\"/deepseek/61\"},{\"text\":\"deep62\",\"link\":\"/deepseek/62\"},{\"text\":\"deep63\",\"link\":\"/deepseek/63\"},{\"text\":\"deep64\",\"link\":\"/deepseek/64\"},{\"text\":\"deep65\",\"link\":\"/deepseek/65\"},{\"text\":\"deep66\",\"link\":\"/deepseek/66\"},{\"text\":\"deep67\",\"link\":\"/deepseek/67\"},{\"text\":\"deep68\",\"link\":\"/deepseek/68\"}]},{\"text\":\"quotes\",\"activeMatch\":\"^/quotes/\",\"items\":[{\"text\":\"quotes1\",\"link\":\"/quotes/1\"},{\"text\":\"quotes2\",\"link\":\"/quotes/2\"},{\"text\":\"quotes3\",\"link\":\"/quotes/3\"},{\"text\":\"quotes4\",\"link\":\"/quotes/4\"},{\"text\":\"quotes5\",\"link\":\"/quotes/5\"},{\"text\":\"quotes6\",\"link\":\"/quotes/6\"},{\"text\":\"quotes7\",\"link\":\"/quotes/7\"},{\"text\":\"quotes8\",\"link\":\"/quotes/8\"},{\"text\":\"quotes9\",\"link\":\"/quotes/9\"},{\"text\":\"quotes10\",\"link\":\"/quotes/10\"},{\"text\":\"quotes11\",\"link\":\"/quotes/11\"},{\"text\":\"quotes12\",\"link\":\"/quotes/12\"},{\"text\":\"quotes13\",\"link\":\"/quotes/13\"},{\"text\":\"quotes14\",\"link\":\"/quotes/14\"},{\"text\":\"quotes15\",\"link\":\"/quotes/15\"},{\"text\":\"quotes16\",\"link\":\"/quotes/16\"},{\"text\":\"quotes17\",\"link\":\"/quotes/17\"},{\"text\":\"quotes18\",\"link\":\"/quotes/18\"},{\"text\":\"quotes19\",\"link\":\"/quotes/19\"},{\"text\":\"quotes20\",\"link\":\"/quotes/20\"},{\"text\":\"quotes21\",\"link\":\"/quotes/21\"},{\"text\":\"quotes22\",\"link\":\"/quotes/22\"},{\"text\":\"quotes23\",\"link\":\"/quotes/23\"},{\"text\":\"quotes24\",\"link\":\"/quotes/24\"},{\"text\":\"quotes25\",\"link\":\"/quotes/25\"},{\"text\":\"quotes26\",\"link\":\"/quotes/26\"},{\"text\":\"quotes27\",\"link\":\"/quotes/27\"},{\"text\":\"quotes28\",\"link\":\"/quotes/28\"},{\"text\":\"quotes29\",\"link\":\"/quotes/29\"},{\"text\":\"quotes30\",\"link\":\"/quotes/30\"},{\"text\":\"quotes31\",\"link\":\"/quotes/31\"},{\"text\":\"quotes32\",\"link\":\"/quotes/32\"},{\"text\":\"quotes33\",\"link\":\"/quotes/33\"},{\"text\":\"quotes34\",\"link\":\"/quotes/34\"},{\"text\":\"quotes35\",\"link\":\"/quotes/35\"},{\"text\":\"quotes36\",\"link\":\"/quotes/36\"},{\"text\":\"quotes37\",\"link\":\"/quotes/37\"},{\"text\":\"quotes38\",\"link\":\"/quotes/38\"},{\"text\":\"quotes39\",\"link\":\"/quotes/39\"},{\"text\":\"quotes40\",\"link\":\"/quotes/40\"},{\"text\":\"quotes41\",\"link\":\"/quotes/41\"},{\"text\":\"quotes42\",\"link\":\"/quotes/42\"},{\"text\":\"quotes43\",\"link\":\"/quotes/43\"},{\"text\":\"quotes44\",\"link\":\"/quotes/44\"},{\"text\":\"quotes45\",\"link\":\"/quotes/45\"},{\"text\":\"quotes46\",\"link\":\"/quotes/46\"},{\"text\":\"quotes47\",\"link\":\"/quotes/47\"},{\"text\":\"quotes48\",\"link\":\"/quotes/48\"},{\"text\":\"quotes49\",\"link\":\"/quotes/49\"},{\"text\":\"quotes50\",\"link\":\"/quotes/50\"},{\"text\":\"quotes51\",\"link\":\"/quotes/51\"},{\"text\":\"quotes52\",\"link\":\"/quotes/52\"},{\"text\":\"quotes53\",\"link\":\"/quotes/53\"},{\"text\":\"quotes54\",\"link\":\"/quotes/54\"},{\"text\":\"quotes55\",\"link\":\"/quotes/55\"},{\"text\":\"quotes56\",\"link\":\"/quotes/56\"},{\"text\":\"quotes57\",\"link\":\"/quotes/57\"},{\"text\":\"quotes58\",\"link\":\"/quotes/58\"},{\"text\":\"quotes59\",\"link\":\"/quotes/59\"},{\"text\":\"quotes60\",\"link\":\"/quotes/60\"},{\"text\":\"quotes61\",\"link\":\"/quotes/61\"},{\"text\":\"quotes62\",\"link\":\"/quotes/62\"},{\"text\":\"quotes63\",\"link\":\"/quotes/63\"},{\"text\":\"quotes64\",\"link\":\"/quotes/64\"},{\"text\":\"quotes65\",\"link\":\"/quotes/65\"},{\"text\":\"quotes66\",\"link\":\"/quotes/66\"},{\"text\":\"quotes67\",\"link\":\"/quotes/67\"},{\"text\":\"quotes68\",\"link\":\"/quotes/68\"}]},{\"text\":\"chatai\",\"activeMatch\":\"^/chatai/\",\"items\":[{\"text\":\"chatai1\",\"link\":\"/chatai/1\"},{\"text\":\"chatai2\",\"link\":\"/chatai/2\"},{\"text\":\"chatai3\",\"link\":\"/chatai/3\"},{\"text\":\"chatai4\",\"link\":\"/chatai/4\"},{\"text\":\"chatai5\",\"link\":\"/chatai/5\"},{\"text\":\"chatai6\",\"link\":\"/chatai/6\"},{\"text\":\"chatai7\",\"link\":\"/chatai/7\"},{\"text\":\"chatai8\",\"link\":\"/chatai/8\"},{\"text\":\"chatai9\",\"link\":\"/chatai/9\"},{\"text\":\"chatai10\",\"link\":\"/chatai/10\"},{\"text\":\"chatai11\",\"link\":\"/chatai/11\"},{\"text\":\"chatai12\",\"link\":\"/chatai/12\"},{\"text\":\"chatai13\",\"link\":\"/chatai/13\"},{\"text\":\"chatai14\",\"link\":\"/chatai/14\"},{\"text\":\"chatai15\",\"link\":\"/chatai/15\"},{\"text\":\"chatai16\",\"link\":\"/chatai/16\"},{\"text\":\"chatai17\",\"link\":\"/chatai/17\"},{\"text\":\"chatai18\",\"link\":\"/chatai/18\"},{\"text\":\"chatai19\",\"link\":\"/chatai/19\"},{\"text\":\"chatai20\",\"link\":\"/chatai/20\"},{\"text\":\"chatai21\",\"link\":\"/chatai/21\"},{\"text\":\"chatai22\",\"link\":\"/chatai/22\"},{\"text\":\"chatai23\",\"link\":\"/chatai/23\"},{\"text\":\"chatai24\",\"link\":\"/chatai/24\"},{\"text\":\"chatai25\",\"link\":\"/chatai/25\"},{\"text\":\"chatai26\",\"link\":\"/chatai/26\"},{\"text\":\"chatai27\",\"link\":\"/chatai/27\"},{\"text\":\"chatai28\",\"link\":\"/chatai/28\"},{\"text\":\"chatai29\",\"link\":\"/chatai/29\"},{\"text\":\"chatai30\",\"link\":\"/chatai/30\"},{\"text\":\"chatai31\",\"link\":\"/chatai/31\"},{\"text\":\"chatai32\",\"link\":\"/chatai/32\"},{\"text\":\"chatai33\",\"link\":\"/chatai/33\"},{\"text\":\"chatai34\",\"link\":\"/chatai/34\"},{\"text\":\"chatai35\",\"link\":\"/chatai/35\"},{\"text\":\"chatai36\",\"link\":\"/chatai/36\"},{\"text\":\"chatai37\",\"link\":\"/chatai/37\"},{\"text\":\"chatai38\",\"link\":\"/chatai/38\"},{\"text\":\"chatai39\",\"link\":\"/chatai/39\"},{\"text\":\"chatai40\",\"link\":\"/chatai/40\"},{\"text\":\"chatai41\",\"link\":\"/chatai/41\"},{\"text\":\"chatai42\",\"link\":\"/chatai/42\"},{\"text\":\"chatai43\",\"link\":\"/chatai/43\"},{\"text\":\"chatai44\",\"link\":\"/chatai/44\"},{\"text\":\"chatai45\",\"link\":\"/chatai/45\"},{\"text\":\"chatai46\",\"link\":\"/chatai/46\"},{\"text\":\"chatai47\",\"link\":\"/chatai/47\"},{\"text\":\"chatai48\",\"link\":\"/chatai/48\"},{\"text\":\"chatai49\",\"link\":\"/chatai/49\"},{\"text\":\"chatai50\",\"link\":\"/chatai/50\"},{\"text\":\"chatai51\",\"link\":\"/chatai/51\"},{\"text\":\"chatai52\",\"link\":\"/chatai/52\"},{\"text\":\"chatai53\",\"link\":\"/chatai/53\"},{\"text\":\"chatai54\",\"link\":\"/chatai/54\"},{\"text\":\"chatai55\",\"link\":\"/chatai/55\"},{\"text\":\"chatai56\",\"link\":\"/chatai/56\"},{\"text\":\"chatai57\",\"link\":\"/chatai/57\"},{\"text\":\"chatai58\",\"link\":\"/chatai/58\"},{\"text\":\"chatai59\",\"link\":\"/chatai/59\"},{\"text\":\"chatai60\",\"link\":\"/chatai/60\"},{\"text\":\"chatai61\",\"link\":\"/chatai/61\"},{\"text\":\"chatai62\",\"link\":\"/chatai/62\"},{\"text\":\"chatai63\",\"link\":\"/chatai/63\"},{\"text\":\"chatai64\",\"link\":\"/chatai/64\"},{\"text\":\"chatai65\",\"link\":\"/chatai/65\"},{\"text\":\"chatai66\",\"link\":\"/chatai/66\"},{\"text\":\"chatai67\",\"link\":\"/chatai/67\"},{\"text\":\"chatai68\",\"link\":\"/chatai/68\"}]},{\"text\":\"library\",\"activeMatch\":\"^/library/\",\"items\":[{\"text\":\"library1\",\"link\":\"/library/1\"},{\"text\":\"library2\",\"link\":\"/library/2\"},{\"text\":\"library3\",\"link\":\"/library/3\"},{\"text\":\"library4\",\"link\":\"/library/4\"},{\"text\":\"library5\",\"link\":\"/library/5\"},{\"text\":\"library6\",\"link\":\"/library/6\"},{\"text\":\"library7\",\"link\":\"/library/7\"},{\"text\":\"library8\",\"link\":\"/library/8\"},{\"text\":\"library9\",\"link\":\"/library/9\"},{\"text\":\"library10\",\"link\":\"/library/10\"},{\"text\":\"library11\",\"link\":\"/library/11\"},{\"text\":\"library12\",\"link\":\"/library/12\"},{\"text\":\"library13\",\"link\":\"/library/13\"},{\"text\":\"library14\",\"link\":\"/library/14\"},{\"text\":\"library15\",\"link\":\"/library/15\"},{\"text\":\"library16\",\"link\":\"/library/16\"},{\"text\":\"library17\",\"link\":\"/library/17\"},{\"text\":\"library18\",\"link\":\"/library/18\"},{\"text\":\"library19\",\"link\":\"/library/19\"},{\"text\":\"library20\",\"link\":\"/library/20\"},{\"text\":\"library21\",\"link\":\"/library/21\"},{\"text\":\"library22\",\"link\":\"/library/22\"},{\"text\":\"library23\",\"link\":\"/library/23\"},{\"text\":\"library24\",\"link\":\"/library/24\"},{\"text\":\"library25\",\"link\":\"/library/25\"},{\"text\":\"library26\",\"link\":\"/library/26\"},{\"text\":\"library27\",\"link\":\"/library/27\"},{\"text\":\"library28\",\"link\":\"/library/28\"},{\"text\":\"library29\",\"link\":\"/library/29\"},{\"text\":\"library30\",\"link\":\"/library/30\"},{\"text\":\"library31\",\"link\":\"/library/31\"},{\"text\":\"library32\",\"link\":\"/library/32\"},{\"text\":\"library33\",\"link\":\"/library/33\"},{\"text\":\"library34\",\"link\":\"/library/34\"},{\"text\":\"library35\",\"link\":\"/library/35\"},{\"text\":\"library36\",\"link\":\"/library/36\"},{\"text\":\"library37\",\"link\":\"/library/37\"},{\"text\":\"library38\",\"link\":\"/library/38\"},{\"text\":\"library39\",\"link\":\"/library/39\"},{\"text\":\"library40\",\"link\":\"/library/40\"},{\"text\":\"library41\",\"link\":\"/library/41\"},{\"text\":\"library42\",\"link\":\"/library/42\"},{\"text\":\"library43\",\"link\":\"/library/43\"},{\"text\":\"library44\",\"link\":\"/library/44\"},{\"text\":\"library45\",\"link\":\"/library/45\"},{\"text\":\"library46\",\"link\":\"/library/46\"},{\"text\":\"library47\",\"link\":\"/library/47\"},{\"text\":\"library48\",\"link\":\"/library/48\"},{\"text\":\"library49\",\"link\":\"/library/49\"},{\"text\":\"library50\",\"link\":\"/library/50\"},{\"text\":\"library51\",\"link\":\"/library/51\"},{\"text\":\"library52\",\"link\":\"/library/52\"},{\"text\":\"library53\",\"link\":\"/library/53\"},{\"text\":\"library54\",\"link\":\"/library/54\"},{\"text\":\"library55\",\"link\":\"/library/55\"},{\"text\":\"library56\",\"link\":\"/library/56\"},{\"text\":\"library57\",\"link\":\"/library/57\"},{\"text\":\"library58\",\"link\":\"/library/58\"},{\"text\":\"library59\",\"link\":\"/library/59\"},{\"text\":\"library60\",\"link\":\"/library/60\"},{\"text\":\"library61\",\"link\":\"/library/61\"},{\"text\":\"library62\",\"link\":\"/library/62\"},{\"text\":\"library63\",\"link\":\"/library/63\"},{\"text\":\"library64\",\"link\":\"/library/64\"},{\"text\":\"library65\",\"link\":\"/library/65\"},{\"text\":\"library66\",\"link\":\"/library/66\"},{\"text\":\"library67\",\"link\":\"/library/67\"},{\"text\":\"library68\",\"link\":\"/library/68\"}]},{\"text\":\"ecosystem\",\"activeMatch\":\"^/ecosystem/\",\"items\":[{\"text\":\"website\",\"items\":[{\"text\":\"partners\",\"link\":\"/partners/\"},{\"text\":\"website\",\"link\":\"/ecosystem/themes\"},{\"text\":\"deepseekletters\",\"link\":\"/ecosystem/newsletters\"},{\"text\":\"AI Navigation\",\"link\":\"/ecosystem/navigation\"},{\"text\":\"DeepSeek-V3\",\"link\":\"/ecosystem/DeepSeek\"},{\"text\":\"ChatGPT\",\"link\":\"/ecosystem/ChatGPT\"},{\"text\":\"GPT Prompts\",\"link\":\"/ecosystem/Promptes\"},{\"text\":\"474x.com\",\"link\":\"https://www.474x.com\"},{\"text\":\"494x.com\",\"link\":\"https://www.494x.com\"},{\"text\":\"64ii.com\",\"link\":\"https://www.64ii.com\"},{\"text\":\"81oo.com\",\"link\":\"https://www.81oo.com\"}]},{\"text\":\"Library\",\"items\":[{\"text\":\"Vue Router\",\"link\":\"https://e.m44m.com/\"},{\"text\":\"Pinia\",\"link\":\"https://f.m44m.com/\"},{\"text\":\"tool\",\"link\":\"https://www.82ii.com\"}]},{\"text\":\"Vue\",\"items\":[{\"text\":\"Vue Mastery\",\"link\":\"https://g.m44m.com\"},{\"text\":\"Vue School\",\"link\":\"https://h.m44m.com\"}]},{\"text\":\"help\",\"items\":[{\"text\":\"Discord\",\"link\":\"https://i.m44m.com\"},{\"text\":\"GitHub\",\"link\":\"https://github.com/hyaliyun/Ad\"},{\"text\":\"DEV\",\"link\":\"https://www.z2.pw\"}]},{\"text\":\"Ad\",\"items\":[{\"text\":\"blog\",\"link\":\"https://c.m44m.com\"},{\"text\":\"Twitter\",\"link\":\"https://d.m44m.com\"},{\"text\":\"Activity\",\"link\":\"https://e.m44m.com\"},{\"text\":\"CMS\",\"link\":\"https://w.z2.pw\"},{\"text\":\"deepseekmagSheets\",\"link\":\"https://a.z2.pw\"},{\"text\":\"Tailwind\",\"link\":\"https://a.434x.com\"},{\"text\":\"Three.js\",\"link\":\"https://b.434x.com\"},{\"text\":\"youtube\",\"link\":\"https://www.q8q9.com\"}]}]},{\"text\":\"team\",\"link\":\"/about/team\",\"activeMatch\":\"^/about/\"},{\"text\":\"show\",\"activeMatch\":\"^/(guide|style-guide|cookbook|examples)/\",\"items\":[{\"text\":\"donation\",\"link\":\"/drive/donation\"},{\"text\":\"PromptLibrary\",\"link\":\"/drive/PromptLibrary\"},{\"text\":\"prompt\",\"link\":\"/drive/prompt\"},{\"text\":\"Vertex AI\",\"link\":\"/drive/aiprompt\"},{\"text\":\"crypto\",\"link\":\"/drive/team\"},{\"text\":\"partners\",\"link\":\"/partners/\"},{\"text\":\"3kk3.com\",\"link\":\"https://www.3kk3.com\"},{\"text\":\"deepseek\",\"link\":\"https://b.q8q9.com\"},{\"text\":\"deepseekr1\",\"link\":\"https://c.4s5s.com\"},{\"text\":\"deepseekr2\",\"link\":\"https://b.6n7n.com\"},{\"text\":\"deepseekr3\",\"link\":\"https://f.m44m.com\"},{\"text\":\"deepseekr4\",\"link\":\"https://c.q8q9.com\"},{\"text\":\"deepseekr5\",\"link\":\"https://a.l00m.com\"},{\"text\":\"deepseekr6\",\"link\":\"https://g.m44m.com\"}]},{\"text\":\"swap\",\"link\":\"/swap/app\",\"activeMatch\":\"^/swap/\"}],\"sidebar\":{},\"localeLinks\":[{\"link\":\"https://g.m44m.com\",\"text\":\"简体中文\",\"repo\":\"https://github.com/hyaliyun/Ad\"}],\"algolia\":{\"indexName\":\"Ad\",\"appId\":\"ML0LEBN7FQ\",\"Key\":\"21cf9df0734770a2448a9da64a700c22\",\"searchParameters\":{\"facetFilters\":[\"version:v3\"]}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/hyaliyun/Ad/\"}],\"editLink\":{\"repo\":\"hyaliyun/Ad\",\"text\":\"Edit this page on GitHub\"},\"footer\":{\"license\":{\"text\":\"Ad License\",\"link\":\"https://www.m44m.com\"},\"copyright\":\"Copyright © 2014-2025 Ad\"}},\"locales\":{},\"scrollOffset\":[\"header\",\".VPLocalNav\"],\"cleanUrls\":false}");</script>
    
  </body>
</html>